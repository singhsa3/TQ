{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Collecting torchaudio==0.10.1\n",
      "  Downloading torchaudio-0.10.1-cp38-cp38-manylinux1_x86_64.whl (2.9 MB)\n",
      "\u001b[K     |████████████████████████████████| 2.9 MB 28.5 MB/s eta 0:00:01\n",
      "\u001b[?25hCollecting attention\n",
      "  Downloading attention-4.1-py3-none-any.whl (8.6 kB)\n",
      "Requirement already satisfied: pyyaml in /usr/lib/python3/dist-packages (5.3.1)\n",
      "Requirement already satisfied: h5py in /usr/lib/python3/dist-packages (2.10.0)\n",
      "Collecting nvidia_smi\n",
      "  Downloading nvidia_smi-0.1.3-py36-none-any.whl (11 kB)\n",
      "Collecting keras==2.9.0rc1\n",
      "  Downloading keras-2.9.0rc1-py2.py3-none-any.whl (1.6 MB)\n",
      "\u001b[K     |████████████████████████████████| 1.6 MB 76.2 MB/s eta 0:00:01\n",
      "\u001b[?25hCollecting tensorflow\n",
      "  Downloading tensorflow-2.9.1-cp38-cp38-manylinux_2_17_x86_64.manylinux2014_x86_64.whl (511.7 MB)\n",
      "\u001b[K     |██████████████████▍             | 293.5 MB 148.1 MB/s eta 0:00:02     |█████████████▊                  | 219.8 MB 139.7 MB/s eta 0:00:03"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "IOPub data rate exceeded.\n",
      "The Jupyter server will temporarily stop sending output\n",
      "to the client in order to avoid crashing it.\n",
      "To change this limit, set the config variable\n",
      "`--ServerApp.iopub_data_rate_limit`.\n",
      "\n",
      "Current values:\n",
      "ServerApp.iopub_data_rate_limit=1000000.0 (bytes/sec)\n",
      "ServerApp.rate_limit_window=3.0 (secs)\n",
      "\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\u001b[K     |████████████████████████████████| 511.7 MB 100 kB/s s eta 0:00:01\n",
      "\u001b[?25hCollecting librosa\n",
      "  Downloading librosa-0.9.2-py3-none-any.whl (214 kB)\n",
      "\u001b[K     |████████████████████████████████| 214 kB 123.9 MB/s eta 0:00:01\n",
      "\u001b[?25hRequirement already satisfied: matplotlib in /home/ubuntu/.local/lib/python3.8/site-packages (3.5.2)\n",
      "Collecting pickle5\n",
      "  Downloading pickle5-0.0.11.tar.gz (132 kB)\n",
      "\u001b[K     |████████████████████████████████| 132 kB 133.3 MB/s eta 0:00:01\n",
      "\u001b[?25hRequirement already satisfied: Pillow in /usr/lib/python3/dist-packages (7.0.0)\n",
      "Requirement already satisfied: pandas in /usr/lib/python3/dist-packages (0.25.3)\n",
      "Requirement already satisfied: numpy in /home/ubuntu/.local/lib/python3.8/site-packages (1.22.4)\n",
      "Collecting opencv-python\n",
      "  Downloading opencv_python-4.6.0.66-cp36-abi3-manylinux_2_17_x86_64.manylinux2014_x86_64.whl (60.9 MB)\n",
      "\u001b[K     |████████████████████████████████| 60.9 MB 114.5 MB/s eta 0:00:01\n",
      "\u001b[?25hCollecting numba\n",
      "  Downloading numba-0.55.2-cp38-cp38-manylinux2014_x86_64.manylinux_2_17_x86_64.whl (3.4 MB)\n",
      "\u001b[K     |████████████████████████████████| 3.4 MB 115.3 MB/s eta 0:00:01\n",
      "\u001b[?25hCollecting torch==1.10.1\n",
      "  Downloading torch-1.10.1-cp38-cp38-manylinux1_x86_64.whl (881.9 MB)\n",
      "\u001b[K     |███████████▊                    | 323.3 MB 136.0 MB/s eta 0:00:05     |█████████▋                      | 265.2 MB 141.8 MB/s eta 0:00:05"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "IOPub data rate exceeded.\n",
      "The Jupyter server will temporarily stop sending output\n",
      "to the client in order to avoid crashing it.\n",
      "To change this limit, set the config variable\n",
      "`--ServerApp.iopub_data_rate_limit`.\n",
      "\n",
      "Current values:\n",
      "ServerApp.iopub_data_rate_limit=1000000.0 (bytes/sec)\n",
      "ServerApp.rate_limit_window=3.0 (secs)\n",
      "\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\u001b[K     |██████████████████████████▊     | 736.6 MB 141.7 MB/s eta 0:00:02"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "IOPub data rate exceeded.\n",
      "The Jupyter server will temporarily stop sending output\n",
      "to the client in order to avoid crashing it.\n",
      "To change this limit, set the config variable\n",
      "`--ServerApp.iopub_data_rate_limit`.\n",
      "\n",
      "Current values:\n",
      "ServerApp.iopub_data_rate_limit=1000000.0 (bytes/sec)\n",
      "ServerApp.rate_limit_window=3.0 (secs)\n",
      "\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\u001b[K     |████████████████████████████████| 881.9 MB 28 kB/s \n",
      "\u001b[?25hRequirement already satisfied: six>=1.12.0 in /usr/lib/python3/dist-packages (from nvidia_smi) (1.14.0)\n",
      "Collecting pytest>=4.3.1\n",
      "  Downloading pytest-7.1.2-py3-none-any.whl (297 kB)\n",
      "\u001b[K     |████████████████████████████████| 297 kB 122.4 MB/s eta 0:00:01\n",
      "\u001b[?25hCollecting sorcery>=0.1.0\n",
      "  Downloading sorcery-0.2.2-py3-none-any.whl (16 kB)\n",
      "Collecting absl-py>=1.0.0\n",
      "  Downloading absl_py-1.1.0-py3-none-any.whl (123 kB)\n",
      "\u001b[K     |████████████████████████████████| 123 kB 82.3 MB/s eta 0:00:01\n",
      "\u001b[?25hRequirement already satisfied: termcolor>=1.1.0 in /usr/lib/python3/dist-packages (from tensorflow) (1.1.0)\n",
      "Requirement already satisfied: setuptools in /usr/lib/python3/dist-packages (from tensorflow) (45.2.0)\n",
      "Requirement already satisfied: wrapt>=1.11.0 in /usr/lib/python3/dist-packages (from tensorflow) (1.11.2)\n",
      "Collecting libclang>=13.0.0\n",
      "  Downloading libclang-14.0.1-py2.py3-none-manylinux1_x86_64.whl (14.5 MB)\n",
      "\u001b[K     |████████████████████████████████| 14.5 MB 79.0 MB/s eta 0:00:01\n",
      "\u001b[?25hCollecting tensorflow-estimator<2.10.0,>=2.9.0rc0\n",
      "  Downloading tensorflow_estimator-2.9.0-py2.py3-none-any.whl (438 kB)\n",
      "\u001b[K     |████████████████████████████████| 438 kB 77.3 MB/s eta 0:00:01██████████████▏  | 399 kB 77.3 MB/s eta 0:00:01\n",
      "\u001b[?25hRequirement already satisfied: opt-einsum>=2.3.2 in /usr/lib/python3/dist-packages (from tensorflow) (3.3.0)\n",
      "Requirement already satisfied: protobuf<3.20,>=3.9.2 in /usr/lib/python3/dist-packages (from tensorflow) (3.11.4)\n",
      "Requirement already satisfied: gast<=0.4.0,>=0.2.1 in /usr/lib/python3/dist-packages (from tensorflow) (0.4.0)\n",
      "Requirement already satisfied: keras-preprocessing>=1.1.1 in /usr/lib/python3/dist-packages (from tensorflow) (1.1.2)\n",
      "Collecting tensorflow-io-gcs-filesystem>=0.23.1\n",
      "  Downloading tensorflow_io_gcs_filesystem-0.26.0-cp38-cp38-manylinux_2_12_x86_64.manylinux2010_x86_64.whl (2.4 MB)\n",
      "\u001b[K     |████████████████████████████████| 2.4 MB 123.1 MB/s eta 0:00:01\n",
      "\u001b[?25hRequirement already satisfied: astunparse>=1.6.0 in /usr/lib/python3/dist-packages (from tensorflow) (1.6.2)\n",
      "Requirement already satisfied: packaging in /usr/lib/python3/dist-packages (from tensorflow) (20.3)\n",
      "Collecting tensorboard<2.10,>=2.9\n",
      "  Downloading tensorboard-2.9.1-py3-none-any.whl (5.8 MB)\n",
      "\u001b[K     |████████████████████████████████| 5.8 MB 117.4 MB/s eta 0:00:01\n",
      "\u001b[?25hRequirement already satisfied: typing-extensions>=3.6.6 in /home/ubuntu/.local/lib/python3.8/site-packages (from tensorflow) (4.2.0)\n",
      "Requirement already satisfied: google-pasta>=0.1.1 in /usr/lib/python3/dist-packages (from tensorflow) (0.2.0)\n",
      "Requirement already satisfied: grpcio<2.0,>=1.24.3 in /usr/lib/python3/dist-packages (from tensorflow) (1.29.1)\n",
      "Requirement already satisfied: flatbuffers<2,>=1.12 in /usr/lib/python3/dist-packages (from tensorflow) (1.12)\n",
      "Requirement already satisfied: joblib>=0.14 in /home/ubuntu/.local/lib/python3.8/site-packages (from librosa) (1.1.0)\n",
      "Collecting pooch>=1.0\n",
      "  Downloading pooch-1.6.0-py3-none-any.whl (56 kB)\n",
      "\u001b[K     |████████████████████████████████| 56 kB 5.8 MB/s  eta 0:00:01\n",
      "\u001b[?25hRequirement already satisfied: scikit-learn>=0.19.1 in /usr/lib/python3/dist-packages (from librosa) (0.22.2.post1)\n",
      "Collecting soundfile>=0.10.2\n",
      "  Downloading SoundFile-0.10.3.post1-py2.py3-none-any.whl (21 kB)\n",
      "Collecting resampy>=0.2.2\n",
      "  Downloading resampy-0.3.0-py3-none-any.whl (3.1 MB)\n",
      "\u001b[K     |████████████████████████████████| 3.1 MB 90.7 MB/s eta 0:00:01\n",
      "\u001b[?25hCollecting audioread>=2.1.9\n",
      "  Downloading audioread-2.1.9.tar.gz (377 kB)\n",
      "\u001b[K     |████████████████████████████████| 377 kB 78.6 MB/s eta 0:00:01��█████████████             | 225 kB 78.6 MB/s eta 0:00:01\n",
      "\u001b[?25hRequirement already satisfied: scipy>=1.2.0 in /home/ubuntu/.local/lib/python3.8/site-packages (from librosa) (1.8.1)\n",
      "Requirement already satisfied: decorator>=4.0.10 in /usr/lib/python3/dist-packages (from librosa) (4.4.2)\n",
      "Requirement already satisfied: python-dateutil>=2.7 in /home/ubuntu/.local/lib/python3.8/site-packages (from matplotlib) (2.8.2)\n",
      "Requirement already satisfied: kiwisolver>=1.0.1 in /usr/lib/python3/dist-packages (from matplotlib) (1.0.1)\n",
      "Requirement already satisfied: cycler>=0.10 in /usr/lib/python3/dist-packages (from matplotlib) (0.10.0)\n",
      "Requirement already satisfied: fonttools>=4.22.0 in /home/ubuntu/.local/lib/python3.8/site-packages (from matplotlib) (4.33.3)\n",
      "Requirement already satisfied: pyparsing>=2.2.1 in /usr/lib/python3/dist-packages (from matplotlib) (2.4.6)\n",
      "Collecting llvmlite<0.39,>=0.38.0rc1\n",
      "  Downloading llvmlite-0.38.1-cp38-cp38-manylinux_2_17_x86_64.manylinux2014_x86_64.whl (34.5 MB)\n",
      "\u001b[K     |████████████████████████████████| 34.5 MB 117.9 MB/s eta 0:00:01.9 MB/s eta 0:00:01\n",
      "\u001b[?25hCollecting tomli>=1.0.0\n",
      "  Downloading tomli-2.0.1-py3-none-any.whl (12 kB)\n",
      "Collecting iniconfig\n",
      "  Downloading iniconfig-1.1.1-py2.py3-none-any.whl (5.0 kB)\n",
      "Requirement already satisfied: attrs>=19.2.0 in /usr/lib/python3/dist-packages (from pytest>=4.3.1->nvidia_smi) (19.3.0)\n",
      "Collecting py>=1.8.2\n",
      "  Downloading py-1.11.0-py2.py3-none-any.whl (98 kB)\n",
      "\u001b[K     |████████████████████████████████| 98 kB 1.7 MB/s s eta 0:00:01\n",
      "\u001b[?25hCollecting pluggy<2.0,>=0.12\n",
      "  Downloading pluggy-1.0.0-py2.py3-none-any.whl (13 kB)\n",
      "Collecting asttokens\n",
      "  Downloading asttokens-2.0.5-py2.py3-none-any.whl (20 kB)\n",
      "Collecting littleutils>=0.2.1\n",
      "  Downloading littleutils-0.2.2.tar.gz (6.6 kB)\n",
      "Collecting executing\n",
      "  Downloading executing-0.8.3-py2.py3-none-any.whl (16 kB)\n",
      "Collecting werkzeug>=1.0.1\n",
      "  Downloading Werkzeug-2.1.2-py3-none-any.whl (224 kB)\n",
      "\u001b[K     |████████████████████████████████| 224 kB 117.3 MB/s eta 0:00:01\n",
      "\u001b[?25hRequirement already satisfied: markdown>=2.6.8 in /usr/lib/python3/dist-packages (from tensorboard<2.10,>=2.9->tensorflow) (3.1.1)\n",
      "Collecting tensorboard-plugin-wit>=1.6.0\n",
      "  Downloading tensorboard_plugin_wit-1.8.1-py3-none-any.whl (781 kB)\n",
      "\u001b[K     |████████████████████████████████| 781 kB 119.7 MB/s eta 0:00:01\n",
      "\u001b[?25hRequirement already satisfied: requests<3,>=2.21.0 in /home/ubuntu/.local/lib/python3.8/site-packages (from tensorboard<2.10,>=2.9->tensorflow) (2.27.1)\n",
      "Collecting google-auth<3,>=1.6.3\n",
      "  Downloading google_auth-2.9.0-py2.py3-none-any.whl (167 kB)\n",
      "\u001b[K     |████████████████████████████████| 167 kB 124.6 MB/s eta 0:00:01\n",
      "\u001b[?25hCollecting tensorboard-data-server<0.7.0,>=0.6.0\n",
      "  Downloading tensorboard_data_server-0.6.1-py3-none-manylinux2010_x86_64.whl (4.9 MB)\n",
      "\u001b[K     |████████████████████████████████| 4.9 MB 74.5 MB/s eta 0:00:01\n",
      "\u001b[?25hRequirement already satisfied: wheel>=0.26 in /usr/lib/python3/dist-packages (from tensorboard<2.10,>=2.9->tensorflow) (0.34.2)\n",
      "Requirement already satisfied: google-auth-oauthlib<0.5,>=0.4.1 in /usr/lib/python3/dist-packages (from tensorboard<2.10,>=2.9->tensorflow) (0.4.1)\n",
      "Requirement already satisfied: appdirs>=1.3.0 in /usr/lib/python3/dist-packages (from pooch>=1.0->librosa) (1.4.3)\n",
      "Requirement already satisfied: cffi>=1.0 in /home/ubuntu/.local/lib/python3.8/site-packages (from soundfile>=0.10.2->librosa) (1.15.0)\n",
      "Requirement already satisfied: idna<4,>=2.5; python_version >= \"3\" in /usr/lib/python3/dist-packages (from requests<3,>=2.21.0->tensorboard<2.10,>=2.9->tensorflow) (2.8)\n",
      "Requirement already satisfied: certifi>=2017.4.17 in /usr/lib/python3/dist-packages (from requests<3,>=2.21.0->tensorboard<2.10,>=2.9->tensorflow) (2019.11.28)\n",
      "Requirement already satisfied: urllib3<1.27,>=1.21.1 in /usr/lib/python3/dist-packages (from requests<3,>=2.21.0->tensorboard<2.10,>=2.9->tensorflow) (1.25.8)\n",
      "Requirement already satisfied: charset-normalizer~=2.0.0; python_version >= \"3\" in /home/ubuntu/.local/lib/python3.8/site-packages (from requests<3,>=2.21.0->tensorboard<2.10,>=2.9->tensorflow) (2.0.12)\n",
      "Requirement already satisfied: pyasn1-modules>=0.2.1 in /usr/lib/python3/dist-packages (from google-auth<3,>=1.6.3->tensorboard<2.10,>=2.9->tensorflow) (0.2.1)\n",
      "Requirement already satisfied: cachetools<6.0,>=2.0.0 in /usr/lib/python3/dist-packages (from google-auth<3,>=1.6.3->tensorboard<2.10,>=2.9->tensorflow) (4.0.0)\n",
      "Requirement already satisfied: rsa<5,>=3.1.4; python_version >= \"3.6\" in /usr/lib/python3/dist-packages (from google-auth<3,>=1.6.3->tensorboard<2.10,>=2.9->tensorflow) (4.0)\n",
      "Requirement already satisfied: pycparser in /home/ubuntu/.local/lib/python3.8/site-packages (from cffi>=1.0->soundfile>=0.10.2->librosa) (2.21)\n",
      "Building wheels for collected packages: pickle5, audioread, littleutils\n",
      "  Building wheel for pickle5 (setup.py) ... \u001b[?25ldone\n",
      "\u001b[?25h  Created wheel for pickle5: filename=pickle5-0.0.11-cp38-cp38-linux_x86_64.whl size=262066 sha256=a1695534a251968db86a452b5b0f6cc98b89196036f9390a30e682a8d5df0aeb\n",
      "  Stored in directory: /home/ubuntu/.cache/pip/wheels/25/d4/61/dbd8edd1a0d656be7b4267c85db3b61951eb60016a0154a122\n",
      "  Building wheel for audioread (setup.py) ... \u001b[?25ldone\n",
      "\u001b[?25h  Created wheel for audioread: filename=audioread-2.1.9-py3-none-any.whl size=23142 sha256=2ea8cf2dcbaaf28c71ad7897b36e225a20a27a975aeb2305a8511c4e645213ad\n",
      "  Stored in directory: /home/ubuntu/.cache/pip/wheels/49/5a/e4/df590783499a992a88de6c0898991d1167453a3196d0d1eeb7\n",
      "  Building wheel for littleutils (setup.py) ... \u001b[?25ldone\n",
      "\u001b[?25h  Created wheel for littleutils: filename=littleutils-0.2.2-py3-none-any.whl size=7048 sha256=ef2b42bd5cd9f6d6906a1f1cda9a78e0a716717130eab85212707ec0c0cbd548\n",
      "  Stored in directory: /home/ubuntu/.cache/pip/wheels/6a/33/c4/0ef84d7f5568c2823e3d63a6e08988852fb9e4bc822034870a\n",
      "Successfully built pickle5 audioread littleutils\n",
      "Installing collected packages: torch, torchaudio, absl-py, keras, libclang, tensorflow-estimator, tensorflow-io-gcs-filesystem, werkzeug, tensorboard-plugin-wit, google-auth, tensorboard-data-server, tensorboard, tensorflow, attention, tomli, iniconfig, py, pluggy, pytest, asttokens, littleutils, executing, sorcery, nvidia-smi, pooch, llvmlite, numba, soundfile, resampy, audioread, librosa, pickle5, opencv-python\n",
      "\u001b[33m  WARNING: The scripts convert-caffe2-to-onnx, convert-onnx-to-caffe2 and torchrun are installed in '/home/ubuntu/.local/bin' which is not on PATH.\n",
      "  Consider adding this directory to PATH or, if you prefer to suppress this warning, use --no-warn-script-location.\u001b[0m\n",
      "\u001b[33m  WARNING: The script tensorboard is installed in '/home/ubuntu/.local/bin' which is not on PATH.\n",
      "  Consider adding this directory to PATH or, if you prefer to suppress this warning, use --no-warn-script-location.\u001b[0m\n",
      "\u001b[33m  WARNING: The scripts estimator_ckpt_converter, import_pb_to_tensorboard, saved_model_cli, tensorboard, tf_upgrade_v2, tflite_convert, toco and toco_from_protos are installed in '/home/ubuntu/.local/bin' which is not on PATH.\n",
      "  Consider adding this directory to PATH or, if you prefer to suppress this warning, use --no-warn-script-location.\u001b[0m\n",
      "\u001b[33m  WARNING: The scripts py.test and pytest are installed in '/home/ubuntu/.local/bin' which is not on PATH.\n",
      "  Consider adding this directory to PATH or, if you prefer to suppress this warning, use --no-warn-script-location.\u001b[0m\n",
      "Successfully installed absl-py-1.1.0 asttokens-2.0.5 attention-4.1 audioread-2.1.9 executing-0.8.3 google-auth-2.9.0 iniconfig-1.1.1 keras-2.9.0rc1 libclang-14.0.1 librosa-0.9.2 littleutils-0.2.2 llvmlite-0.38.1 numba-0.55.2 nvidia-smi-0.1.3 opencv-python-4.6.0.66 pickle5-0.0.11 pluggy-1.0.0 pooch-1.6.0 py-1.11.0 pytest-7.1.2 resampy-0.3.0 sorcery-0.2.2 soundfile-0.10.3.post1 tensorboard-2.9.1 tensorboard-data-server-0.6.1 tensorboard-plugin-wit-1.8.1 tensorflow-2.9.1 tensorflow-estimator-2.9.0 tensorflow-io-gcs-filesystem-0.26.0 tomli-2.0.1 torch-1.10.1 torchaudio-0.10.1 werkzeug-2.1.2\n"
     ]
    }
   ],
   "source": [
    "!pip install torchaudio==0.10.1 attention pyyaml h5py nvidia_smi keras==2.9.0rc1 tensorflow librosa matplotlib pickle5 Pillow pandas numpy opencv-python numba #gdown"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [],
   "source": [
    "from tensorflow.tools.docs import doc_controls"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/"
    },
    "id": "Q6cTyZVydgca",
    "outputId": "222bd80d-a8df-41e6-cb7b-316a13a7e8d2"
   },
   "outputs": [],
   "source": [
    "import librosa, librosa.display\n",
    "import matplotlib.pyplot as plt\n",
    "\n",
    "import os\n",
    "import glob\n",
    "\n",
    "import cv2\n",
    "import pickle5 as pickle\n",
    "from PIL import Image as im"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {
    "id": "4NblImFddp9T"
   },
   "outputs": [],
   "source": [
    "pathG='../data' \n",
    "DATASET_PATH0 = pathG+\"/w2v2/w2v2L0\"\n",
    "DATASET_PATH4 = pathG+\"/w2v2/w2v2L4\"\n",
    "DATASET_PATH8 = pathG+\"/w2v2/w2v2L8\"\n",
    "DATASET_PATHS = [DATASET_PATH0,DATASET_PATH4,DATASET_PATH8]\n",
    "DATASET_PATH = DATASET_PATHS[0]\n",
    "#https://stackoverflow.com/questions/10443295/combine-3-separate-numpy-arrays-to-an-rgb-image-in-python"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {},
   "outputs": [],
   "source": [
    "therapist='Yared Alemu'\n",
    "emotion='fear'"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {
    "id": "Dyfp0YeCwBMJ"
   },
   "outputs": [],
   "source": [
    "# Get data list\n",
    "\"\"\"\n",
    "Created on Tue Jun  7 20:48:17 2022\n",
    "\n",
    "@author: sanjeev\n",
    "\"\"\"\n",
    "\n",
    "import argparse\n",
    "import math\n",
    "import sys\n",
    "import time\n",
    "import copy\n",
    "import numpy as np\n",
    "\n",
    "import keras\n",
    "from keras import regularizers\n",
    "from keras.models import Sequential, Model\n",
    "from keras.layers import Dense, Dropout, Flatten, Activation, BatchNormalization #, regularizers\n",
    "from keras.layers.noise import GaussianNoise\n",
    "from keras.layers import Conv2D, MaxPooling2D,AveragePooling2D\n",
    "from keras import backend as K\n",
    "from keras.callbacks import ModelCheckpoint, EarlyStopping\n",
    "from keras.utils.np_utils import to_categorical\n",
    "import tensorflow as tf\n",
    "import models_custom as mcs\n",
    "from keras.models import load_model\n",
    "\n",
    "\n",
    "import os\n",
    "\n",
    "#os.chdir('/media/sanjeev/Data/Pract/Practicum/codesNdata/mycode')\n",
    "#pathG='../data'\n",
    "\n",
    "import pandas as pd\n",
    "df=pd.read_csv(pathG+\"/labels/\"+therapist+\"_\"+emotion+\".csv\")\n",
    "df = df.reset_index()\n",
    "df['name2'] =df['name'].apply (lambda x: x.split(\".\")[0]+\".pickle\")\n",
    "\n",
    "\n",
    "import glob\n",
    "\n",
    "import os\n",
    " \n",
    "filenames= glob.glob(DATASET_PATH+\"/*.pickle\" )\n",
    "filenames = [os.path.basename(x) for x in filenames]\n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {
    "id": "TTNcFKd2FNaG"
   },
   "outputs": [],
   "source": [
    "\n",
    "# This is to delete the rows greater than max size\n",
    "l95=5000\n",
    "df2=df.copy(deep=True)\n",
    "for i,row in df.iterrows():    \n",
    "    fl = DATASET_PATH+\"/\"+row['name2']\n",
    "    try:\n",
    "        with open(fl,\"rb\") as f:\n",
    "            x=pickle.load(f)     \n",
    "        l1 = x[0].shape[0]\n",
    "        w1 = x[0].shape[1] \n",
    "        if l1> l95:\n",
    "            try:\n",
    "            #print(i)\n",
    "                df2=df2.drop(df.iloc[i].name)\n",
    "            except:\n",
    "                print(i,l1)\n",
    "                print(\"encountered and error\")\n",
    "    except:\n",
    "        pass\n",
    "\n",
    "df= df2.reset_index()\n",
    "x=None"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/",
     "height": 206
    },
    "id": "hqEZFlE-R3fW",
    "outputId": "69aee205-8c26-4dca-e7c2-91e9b40c9243"
   },
   "outputs": [],
   "source": [
    "fl='test.pickle'\n",
    "with open(fl,\"rb\") as f:\n",
    "    x=pickle.load(f)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "metadata": {
    "id": "z_Nby6tPCYiM"
   },
   "outputs": [],
   "source": [
    "# Normalizing data and creating an array\n",
    "def create_arr(fl,l95, height,width,img):\n",
    "    if img==1:\n",
    "        pxl=255\n",
    "    else:\n",
    "        pxl=1  \n",
    "    with open(fl,\"rb\") as f:\n",
    "        x=pickle.load(f) \n",
    "    l1 = x[0].shape[0]\n",
    "    try:\n",
    "        #print(l95-l1+1)\n",
    "        x=np.pad(x.cpu().detach().numpy(), ((0,0), (10,l95-l1+1), (0, 0)), 'constant')\n",
    "        c= x[0]\n",
    "        #print(c.shape)\n",
    "        if img==1:      \n",
    "            b = np.max(c)\n",
    "            a = np.min(c)\n",
    "            c =pxl*(c-a)/(b-a)\n",
    "            c=c.astype(np.uint8)\n",
    "            data=im.fromarray(c)\n",
    "            data = data.resize((height,width) )\n",
    "            arr=np.array(data)\n",
    "            arr = arr.reshape(height,width,1)\n",
    "            x=None\n",
    "        else:        \n",
    "            arr=x[0]  \n",
    "            arr = arr.reshape(arr.shape[0],arr.shape[1],1)\n",
    "            #print(arr.shape)\n",
    "    except Exception as e: # work on python 2.x\n",
    "        #print(\"oops\")\n",
    "        print(str(e))\n",
    "        arr= None     \n",
    "    return arr"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "(10, 20, 3)"
      ]
     },
     "execution_count": 10,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "\n",
    "A=np.random.randint(1000, size=(10,20,3))\n",
    "A.shape\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "(1, 10, 20, 3)"
      ]
     },
     "execution_count": 11,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "np.expand_dims(A, axis=0).shape"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "metadata": {
    "id": "TKLK20t_YVGS"
   },
   "outputs": [],
   "source": [
    "from os.path import exists\n",
    "# Converting to image\n",
    "def imgconvert(df, l95,DATASET_PATH,height=500, width=64, img=1):\n",
    "    df=df.drop(columns=['level_0'])\n",
    "    df=df.reset_index()\n",
    "    arrlist0=[]\n",
    "    for DATASET_PATH in DATASET_PATHS:\n",
    "        fl= DATASET_PATH +\"/\"+df.iloc[0]['name2']           \n",
    "        if exists(fl)==True:\n",
    "            arrlist0.append(create_arr(fl,l95, height,width,img))\n",
    "        else:\n",
    "            print(fl+\" Does not exists\")\n",
    "    arr= np.concatenate(tuple(arrlist0), axis=2)\n",
    "    #arr = arr.reshape(1, height,width,len(DATASET_PATHS))\n",
    "    arr= np.expand_dims(arr, axis=0)\n",
    "    #print(arr.shape)\n",
    "    #fl= DATASET_PATH +\"/\"+df.iloc[0]['name2']  \n",
    "    #arr=create_arr(fl,l95, height,width,img)\n",
    "    \n",
    "    idx=[]\n",
    "    for i,row in df.iterrows():\n",
    "        #fl = DATASET_PATH+\"/\"+row['name2']\n",
    "        arrlist2=[]\n",
    "        \n",
    "        for DATASET_PATH in DATASET_PATHS:            \n",
    "            fl = DATASET_PATH+\"/\"+row['name2'] \n",
    "            if exists(fl)==True:\n",
    "                arrlist2.append(create_arr(fl,l95, height,width,img)) \n",
    "            else:\n",
    "                print(fl+\" Does not exists\")\n",
    "               \n",
    "        try:\n",
    "            #arr2=create_arr(fl,l95, height,width,img)            \n",
    "            arr2 = np.concatenate(tuple(arrlist2), axis=2)\n",
    "            #arr2 = arr2.reshape(1, height,width,len(DATASET_PATHS))\n",
    "            arr2= np.expand_dims(arr2, axis=0)\n",
    "            arr = np.vstack((arr,arr2))\n",
    "\n",
    "                \n",
    "            idx.append(i)\n",
    "            x=None            \n",
    "        except Exception as e: \n",
    "            #print(\"dhat teri\")\n",
    "            print(str(e))\n",
    "    \n",
    "    arr =np.delete(arr, (0), axis=0) # First row was dummy row\n",
    "    labels=np.array(df.emotion.iloc[idx])\n",
    "    return arr , labels "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "metadata": {},
   "outputs": [],
   "source": [
    "def split_dataframe(df, chunk_size): \n",
    "    chunks = list()\n",
    "    num_chunks = len(df) // chunk_size + 1\n",
    "    for i in range(num_chunks):\n",
    "        chunks.append(df[i*chunk_size:(i+1)*chunk_size])\n",
    "    return chunks"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 14,
   "metadata": {},
   "outputs": [],
   "source": [
    "from sklearn.model_selection import train_test_split\n",
    "X= df\n",
    "y= df['emotion']\n",
    "X_train, X_test1, y_train, y_test1 = train_test_split(X, y, test_size=0.4, random_state=42)\n",
    "X_val, X_test, y_val, y_test = train_test_split(X_test1, y_test1, test_size=0.5, random_state=42)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 15,
   "metadata": {},
   "outputs": [],
   "source": [
    "imgs=1\n",
    "val_x, val_y =imgconvert(X_val,l95,DATASET_PATH,img=imgs)\n",
    "test_x, test_y =imgconvert(X_val,l95,DATASET_PATH,img=imgs)\n",
    "val_y=val_y.astype(int) \n",
    "test_y=test_y.astype(int) \n",
    "y_val = to_categorical(val_y)\n",
    "y_test= to_categorical(test_y)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "id": "PV5q2H4K4qmq"
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "(8, 500, 64, 3) (8, 2)\n",
      "model does not existing. Creating a new one\n",
      "(500, 64, 3)\n",
      "Epoch 1/150\n",
      "1/1 [==============================] - ETA: 0s - loss: 7.4623 - categorical_accuracy: 0.3750\n",
      "Epoch 1: val_categorical_accuracy improved from -inf to 0.44186, saving model to saved_model/Yared Alemu_fear_shallow\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "WARNING:absl:Found untraced functions such as _jit_compiled_convolution_op, _jit_compiled_convolution_op, _jit_compiled_convolution_op while saving (showing 3 of 3). These functions will not be directly callable after loading.\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "INFO:tensorflow:Assets written to: saved_model/Yared Alemu_fear_shallow/assets\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "INFO:tensorflow:Assets written to: saved_model/Yared Alemu_fear_shallow/assets\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "1/1 [==============================] - 13s 13s/step - loss: 7.4623 - categorical_accuracy: 0.3750 - val_loss: 72883.7422 - val_categorical_accuracy: 0.4419\n",
      "Epoch 2/150\n",
      "1/1 [==============================] - ETA: 0s - loss: 51786.1484 - categorical_accuracy: 0.6250\n",
      "Epoch 2: val_categorical_accuracy did not improve from 0.44186\n",
      "1/1 [==============================] - 1s 1s/step - loss: 51786.1484 - categorical_accuracy: 0.6250 - val_loss: 422635.2188 - val_categorical_accuracy: 0.4419\n",
      "Epoch 3/150\n",
      "1/1 [==============================] - ETA: 0s - loss: 277342.2188 - categorical_accuracy: 0.6250\n",
      "Epoch 3: val_categorical_accuracy improved from 0.44186 to 0.55814, saving model to saved_model/Yared Alemu_fear_shallow\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "WARNING:absl:Found untraced functions such as _jit_compiled_convolution_op, _jit_compiled_convolution_op, _jit_compiled_convolution_op while saving (showing 3 of 3). These functions will not be directly callable after loading.\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "INFO:tensorflow:Assets written to: saved_model/Yared Alemu_fear_shallow/assets\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "INFO:tensorflow:Assets written to: saved_model/Yared Alemu_fear_shallow/assets\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "1/1 [==============================] - 12s 12s/step - loss: 277342.2188 - categorical_accuracy: 0.6250 - val_loss: 152980.6094 - val_categorical_accuracy: 0.5581\n",
      "Epoch 4/150\n",
      "1/1 [==============================] - ETA: 0s - loss: 208244.6562 - categorical_accuracy: 0.3750\n",
      "Epoch 4: val_categorical_accuracy did not improve from 0.55814\n",
      "1/1 [==============================] - 2s 2s/step - loss: 208244.6562 - categorical_accuracy: 0.3750 - val_loss: 775803.0000 - val_categorical_accuracy: 0.5581\n",
      "Epoch 5/150\n",
      "1/1 [==============================] - ETA: 0s - loss: 1017793.8750 - categorical_accuracy: 0.3750\n",
      "Epoch 5: val_categorical_accuracy did not improve from 0.55814\n",
      "1/1 [==============================] - 1s 1s/step - loss: 1017793.8750 - categorical_accuracy: 0.3750 - val_loss: 134529.6094 - val_categorical_accuracy: 0.5581\n",
      "Epoch 6/150\n",
      "1/1 [==============================] - ETA: 0s - loss: 179682.2656 - categorical_accuracy: 0.3750\n",
      "Epoch 6: val_categorical_accuracy did not improve from 0.55814\n",
      "1/1 [==============================] - 1s 1s/step - loss: 179682.2656 - categorical_accuracy: 0.3750 - val_loss: 14974.9824 - val_categorical_accuracy: 0.4419\n",
      "Epoch 7/150\n",
      "1/1 [==============================] - ETA: 0s - loss: 9639.6309 - categorical_accuracy: 0.6250\n",
      "Epoch 7: val_categorical_accuracy did not improve from 0.55814\n",
      "1/1 [==============================] - 1s 1s/step - loss: 9639.6309 - categorical_accuracy: 0.6250 - val_loss: 22502.6016 - val_categorical_accuracy: 0.4419\n",
      "Epoch 8/150\n",
      "1/1 [==============================] - ETA: 0s - loss: 14532.1953 - categorical_accuracy: 0.6250\n",
      "Epoch 8: val_categorical_accuracy did not improve from 0.55814\n",
      "1/1 [==============================] - 1s 1s/step - loss: 14532.1953 - categorical_accuracy: 0.6250 - val_loss: 14854.6133 - val_categorical_accuracy: 0.5581\n",
      "Epoch 9/150\n",
      "1/1 [==============================] - ETA: 0s - loss: 25332.8789 - categorical_accuracy: 0.3750\n",
      "Epoch 9: val_categorical_accuracy did not improve from 0.55814\n",
      "1/1 [==============================] - 1s 1s/step - loss: 25332.8789 - categorical_accuracy: 0.3750 - val_loss: 29508.6133 - val_categorical_accuracy: 0.4419\n",
      "Epoch 10/150\n",
      "1/1 [==============================] - ETA: 0s - loss: 19576.6250 - categorical_accuracy: 0.6250\n",
      "Epoch 10: val_categorical_accuracy did not improve from 0.55814\n",
      "1/1 [==============================] - 1s 1s/step - loss: 19576.6250 - categorical_accuracy: 0.6250 - val_loss: 4188.3481 - val_categorical_accuracy: 0.4419\n",
      "Epoch 11/150\n",
      "1/1 [==============================] - ETA: 0s - loss: 2969.3252 - categorical_accuracy: 0.6250\n",
      "Epoch 11: val_categorical_accuracy did not improve from 0.55814\n",
      "1/1 [==============================] - 1s 1s/step - loss: 2969.3252 - categorical_accuracy: 0.6250 - val_loss: 456.8615 - val_categorical_accuracy: 0.4419\n",
      "Epoch 12/150\n",
      "1/1 [==============================] - ETA: 0s - loss: 502.0695 - categorical_accuracy: 0.6250\n",
      "Epoch 12: val_categorical_accuracy did not improve from 0.55814\n",
      "1/1 [==============================] - 1s 1s/step - loss: 502.0695 - categorical_accuracy: 0.6250 - val_loss: 1497.5455 - val_categorical_accuracy: 0.5581\n",
      "Epoch 13/150\n",
      "1/1 [==============================] - ETA: 0s - loss: 1612.0719 - categorical_accuracy: 0.2500\n",
      "Epoch 13: val_categorical_accuracy did not improve from 0.55814\n",
      "1/1 [==============================] - 1s 1s/step - loss: 1612.0719 - categorical_accuracy: 0.2500 - val_loss: 259.5485 - val_categorical_accuracy: 0.4302\n",
      "Epoch 13: early stopping\n",
      "Total memory: 51527024640\n",
      "Free memory: 51046449152\n",
      "Used memory: 480575488\n",
      "(8, 500, 64, 3) (8, 2)\n",
      "Loading existing model\n",
      "Epoch 1/150\n",
      "1/1 [==============================] - ETA: 0s - loss: 200.3688 - categorical_accuracy: 0.7500\n",
      "Epoch 1: val_categorical_accuracy improved from -inf to 0.55814, saving model to saved_model/Yared Alemu_fear_shallow\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "WARNING:absl:Found untraced functions such as _jit_compiled_convolution_op, _jit_compiled_convolution_op, _jit_compiled_convolution_op while saving (showing 3 of 3). These functions will not be directly callable after loading.\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "INFO:tensorflow:Assets written to: saved_model/Yared Alemu_fear_shallow/assets\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "INFO:tensorflow:Assets written to: saved_model/Yared Alemu_fear_shallow/assets\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "1/1 [==============================] - 12s 12s/step - loss: 200.3688 - categorical_accuracy: 0.7500 - val_loss: 780.9520 - val_categorical_accuracy: 0.5581\n",
      "Epoch 2/150\n",
      "1/1 [==============================] - ETA: 0s - loss: 1390.8252 - categorical_accuracy: 0.2500\n",
      "Epoch 2: val_categorical_accuracy did not improve from 0.55814\n",
      "1/1 [==============================] - 1s 1s/step - loss: 1390.8252 - categorical_accuracy: 0.2500 - val_loss: 536.7413 - val_categorical_accuracy: 0.4419\n",
      "Epoch 3/150\n",
      "1/1 [==============================] - ETA: 0s - loss: 296.9050 - categorical_accuracy: 0.7500\n",
      "Epoch 3: val_categorical_accuracy did not improve from 0.55814\n",
      "1/1 [==============================] - 1s 1s/step - loss: 296.9050 - categorical_accuracy: 0.7500 - val_loss: 1224.2720 - val_categorical_accuracy: 0.4419\n",
      "Epoch 4/150\n",
      "1/1 [==============================] - ETA: 0s - loss: 625.4517 - categorical_accuracy: 0.7500\n",
      "Epoch 4: val_categorical_accuracy did not improve from 0.55814\n",
      "1/1 [==============================] - 1s 1s/step - loss: 625.4517 - categorical_accuracy: 0.7500 - val_loss: 1024.8998 - val_categorical_accuracy: 0.4419\n",
      "Epoch 5/150\n",
      "1/1 [==============================] - ETA: 0s - loss: 482.5020 - categorical_accuracy: 0.7500\n",
      "Epoch 5: val_categorical_accuracy did not improve from 0.55814\n",
      "1/1 [==============================] - 1s 1s/step - loss: 482.5020 - categorical_accuracy: 0.7500 - val_loss: 141.4428 - val_categorical_accuracy: 0.4419\n",
      "Epoch 6/150\n",
      "1/1 [==============================] - ETA: 0s - loss: 52.0572 - categorical_accuracy: 0.7500\n",
      "Epoch 6: val_categorical_accuracy did not improve from 0.55814\n",
      "1/1 [==============================] - 1s 1s/step - loss: 52.0572 - categorical_accuracy: 0.7500 - val_loss: 1487.5488 - val_categorical_accuracy: 0.5581\n",
      "Epoch 7/150\n",
      "1/1 [==============================] - ETA: 0s - loss: 2727.0195 - categorical_accuracy: 0.2500\n",
      "Epoch 7: val_categorical_accuracy did not improve from 0.55814\n",
      "1/1 [==============================] - 1s 1s/step - loss: 2727.0195 - categorical_accuracy: 0.2500 - val_loss: 340.1517 - val_categorical_accuracy: 0.5581\n",
      "Epoch 8/150\n",
      "1/1 [==============================] - ETA: 0s - loss: 646.6431 - categorical_accuracy: 0.2500\n",
      "Epoch 8: val_categorical_accuracy did not improve from 0.55814\n",
      "1/1 [==============================] - 1s 1s/step - loss: 646.6431 - categorical_accuracy: 0.2500 - val_loss: 2402.8850 - val_categorical_accuracy: 0.4419\n",
      "Epoch 9/150\n",
      "1/1 [==============================] - ETA: 0s - loss: 1168.2505 - categorical_accuracy: 0.7500\n",
      "Epoch 9: val_categorical_accuracy did not improve from 0.55814\n",
      "1/1 [==============================] - 1s 1s/step - loss: 1168.2505 - categorical_accuracy: 0.7500 - val_loss: 3938.8875 - val_categorical_accuracy: 0.4419\n",
      "Epoch 10/150\n",
      "1/1 [==============================] - ETA: 0s - loss: 1935.4507 - categorical_accuracy: 0.7500\n",
      "Epoch 10: val_categorical_accuracy did not improve from 0.55814\n",
      "1/1 [==============================] - 1s 1s/step - loss: 1935.4507 - categorical_accuracy: 0.7500 - val_loss: 4562.1133 - val_categorical_accuracy: 0.4419\n",
      "Epoch 11/150\n",
      "1/1 [==============================] - ETA: 0s - loss: 2253.5076 - categorical_accuracy: 0.7500\n",
      "Epoch 11: val_categorical_accuracy did not improve from 0.55814\n",
      "1/1 [==============================] - 1s 1s/step - loss: 2253.5076 - categorical_accuracy: 0.7500 - val_loss: 4607.2637 - val_categorical_accuracy: 0.4419\n",
      "Epoch 11: early stopping\n",
      "Total memory: 51527024640\n",
      "Free memory: 51046449152\n",
      "Used memory: 480575488\n",
      "(8, 500, 64, 3) (8, 1)\n",
      "Loading existing model\n",
      "Epoch 1/150\n",
      "1/1 [==============================] - ETA: 0s - loss: 8306.7129 - categorical_accuracy: 0.0000e+00\n",
      "Epoch 1: val_categorical_accuracy improved from -inf to 0.44186, saving model to saved_model/Yared Alemu_fear_shallow\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "WARNING:absl:Found untraced functions such as _jit_compiled_convolution_op, _jit_compiled_convolution_op, _jit_compiled_convolution_op while saving (showing 3 of 3). These functions will not be directly callable after loading.\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "INFO:tensorflow:Assets written to: saved_model/Yared Alemu_fear_shallow/assets\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "INFO:tensorflow:Assets written to: saved_model/Yared Alemu_fear_shallow/assets\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "1/1 [==============================] - 13s 13s/step - loss: 8306.7129 - categorical_accuracy: 0.0000e+00 - val_loss: 4010.5806 - val_categorical_accuracy: 0.4419\n",
      "Epoch 2/150\n",
      "1/1 [==============================] - ETA: 0s - loss: 7252.2935 - categorical_accuracy: 0.0000e+00\n",
      "Epoch 2: val_categorical_accuracy did not improve from 0.44186\n",
      "1/1 [==============================] - 1s 1s/step - loss: 7252.2935 - categorical_accuracy: 0.0000e+00 - val_loss: 3042.4180 - val_categorical_accuracy: 0.4419\n",
      "Epoch 3/150\n",
      "1/1 [==============================] - ETA: 0s - loss: 5525.3818 - categorical_accuracy: 0.0000e+00\n",
      "Epoch 3: val_categorical_accuracy did not improve from 0.44186\n",
      "1/1 [==============================] - 1s 1s/step - loss: 5525.3818 - categorical_accuracy: 0.0000e+00 - val_loss: 1906.4669 - val_categorical_accuracy: 0.4419\n",
      "Epoch 4/150\n",
      "1/1 [==============================] - ETA: 0s - loss: 3488.8452 - categorical_accuracy: 0.0000e+00\n",
      "Epoch 4: val_categorical_accuracy did not improve from 0.44186\n",
      "1/1 [==============================] - 1s 1s/step - loss: 3488.8452 - categorical_accuracy: 0.0000e+00 - val_loss: 736.0856 - val_categorical_accuracy: 0.4419\n",
      "Epoch 5/150\n",
      "1/1 [==============================] - ETA: 0s - loss: 1366.4535 - categorical_accuracy: 0.0000e+00\n",
      "Epoch 5: val_categorical_accuracy improved from 0.44186 to 0.55814, saving model to saved_model/Yared Alemu_fear_shallow\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "WARNING:absl:Found untraced functions such as _jit_compiled_convolution_op, _jit_compiled_convolution_op, _jit_compiled_convolution_op while saving (showing 3 of 3). These functions will not be directly callable after loading.\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "INFO:tensorflow:Assets written to: saved_model/Yared Alemu_fear_shallow/assets\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "INFO:tensorflow:Assets written to: saved_model/Yared Alemu_fear_shallow/assets\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "1/1 [==============================] - 12s 12s/step - loss: 1366.4535 - categorical_accuracy: 0.0000e+00 - val_loss: 312.4431 - val_categorical_accuracy: 0.5581\n",
      "Epoch 6/150\n",
      "1/1 [==============================] - ETA: 0s - loss: 657.3507 - categorical_accuracy: 1.0000\n",
      "Epoch 6: val_categorical_accuracy did not improve from 0.55814\n",
      "1/1 [==============================] - 2s 2s/step - loss: 657.3507 - categorical_accuracy: 1.0000 - val_loss: 779.5596 - val_categorical_accuracy: 0.5581\n",
      "Epoch 7/150\n",
      "1/1 [==============================] - ETA: 0s - loss: 1726.9857 - categorical_accuracy: 1.0000\n",
      "Epoch 7: val_categorical_accuracy did not improve from 0.55814\n",
      "1/1 [==============================] - 1s 1s/step - loss: 1726.9857 - categorical_accuracy: 1.0000 - val_loss: 977.1143 - val_categorical_accuracy: 0.5581\n",
      "Epoch 8/150\n",
      "1/1 [==============================] - ETA: 0s - loss: 2206.4890 - categorical_accuracy: 1.0000\n",
      "Epoch 8: val_categorical_accuracy did not improve from 0.55814\n",
      "1/1 [==============================] - 1s 1s/step - loss: 2206.4890 - categorical_accuracy: 1.0000 - val_loss: 1018.9156 - val_categorical_accuracy: 0.5581\n",
      "Epoch 9/150\n",
      "1/1 [==============================] - ETA: 0s - loss: 2279.2139 - categorical_accuracy: 1.0000\n",
      "Epoch 9: val_categorical_accuracy did not improve from 0.55814\n",
      "1/1 [==============================] - 1s 1s/step - loss: 2279.2139 - categorical_accuracy: 1.0000 - val_loss: 964.0459 - val_categorical_accuracy: 0.5349\n",
      "Epoch 10/150\n",
      "1/1 [==============================] - ETA: 0s - loss: 1998.4021 - categorical_accuracy: 1.0000\n",
      "Epoch 10: val_categorical_accuracy did not improve from 0.55814\n",
      "1/1 [==============================] - 1s 1s/step - loss: 1998.4021 - categorical_accuracy: 1.0000 - val_loss: 700.3043 - val_categorical_accuracy: 0.5349\n",
      "Epoch 11/150\n",
      "1/1 [==============================] - ETA: 0s - loss: 1250.4852 - categorical_accuracy: 1.0000\n",
      "Epoch 11: val_categorical_accuracy did not improve from 0.55814\n",
      "1/1 [==============================] - 1s 1s/step - loss: 1250.4852 - categorical_accuracy: 1.0000 - val_loss: 211.1683 - val_categorical_accuracy: 0.4302\n",
      "Epoch 12/150\n",
      "1/1 [==============================] - ETA: 0s - loss: 214.6814 - categorical_accuracy: 0.0000e+00\n",
      "Epoch 12: val_categorical_accuracy did not improve from 0.55814\n",
      "1/1 [==============================] - 1s 1s/step - loss: 214.6814 - categorical_accuracy: 0.0000e+00 - val_loss: 597.0317 - val_categorical_accuracy: 0.4419\n",
      "Epoch 13/150\n",
      "1/1 [==============================] - ETA: 0s - loss: 1067.5417 - categorical_accuracy: 0.0000e+00\n",
      "Epoch 13: val_categorical_accuracy did not improve from 0.55814\n",
      "1/1 [==============================] - 1s 1s/step - loss: 1067.5417 - categorical_accuracy: 0.0000e+00 - val_loss: 545.1239 - val_categorical_accuracy: 0.4419\n",
      "Epoch 14/150\n",
      "1/1 [==============================] - ETA: 0s - loss: 980.4429 - categorical_accuracy: 0.0000e+00\n",
      "Epoch 14: val_categorical_accuracy did not improve from 0.55814\n",
      "1/1 [==============================] - 1s 1s/step - loss: 980.4429 - categorical_accuracy: 0.0000e+00 - val_loss: 590.2380 - val_categorical_accuracy: 0.5581\n",
      "Epoch 15/150\n",
      "1/1 [==============================] - ETA: 0s - loss: 1308.0518 - categorical_accuracy: 1.0000\n",
      "Epoch 15: val_categorical_accuracy did not improve from 0.55814\n",
      "1/1 [==============================] - 1s 1s/step - loss: 1308.0518 - categorical_accuracy: 1.0000 - val_loss: 1181.7291 - val_categorical_accuracy: 0.5581\n",
      "Epoch 15: early stopping\n",
      "Total memory: 51527024640\n",
      "Free memory: 51046449152\n",
      "Used memory: 480575488\n",
      "(8, 500, 64, 3) (8, 2)\n",
      "Loading existing model\n",
      "Epoch 1/150\n",
      "1/1 [==============================] - ETA: 0s - loss: 1271.9629 - categorical_accuracy: 0.5000\n",
      "Epoch 1: val_categorical_accuracy improved from -inf to 0.44186, saving model to saved_model/Yared Alemu_fear_shallow\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "WARNING:absl:Found untraced functions such as _jit_compiled_convolution_op, _jit_compiled_convolution_op, _jit_compiled_convolution_op while saving (showing 3 of 3). These functions will not be directly callable after loading.\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "INFO:tensorflow:Assets written to: saved_model/Yared Alemu_fear_shallow/assets\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "INFO:tensorflow:Assets written to: saved_model/Yared Alemu_fear_shallow/assets\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "1/1 [==============================] - 12s 12s/step - loss: 1271.9629 - categorical_accuracy: 0.5000 - val_loss: 8573.7539 - val_categorical_accuracy: 0.4419\n",
      "Epoch 2/150\n",
      "1/1 [==============================] - ETA: 0s - loss: 7848.1211 - categorical_accuracy: 0.5000\n",
      "Epoch 2: val_categorical_accuracy did not improve from 0.44186\n",
      "1/1 [==============================] - 1s 1s/step - loss: 7848.1211 - categorical_accuracy: 0.5000 - val_loss: 4273.7344 - val_categorical_accuracy: 0.4419\n",
      "Epoch 3/150\n",
      "1/1 [==============================] - ETA: 0s - loss: 3902.7812 - categorical_accuracy: 0.5000\n",
      "Epoch 3: val_categorical_accuracy improved from 0.44186 to 0.55814, saving model to saved_model/Yared Alemu_fear_shallow\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "WARNING:absl:Found untraced functions such as _jit_compiled_convolution_op, _jit_compiled_convolution_op, _jit_compiled_convolution_op while saving (showing 3 of 3). These functions will not be directly callable after loading.\n"
     ]
    }
   ],
   "source": [
    "chunk_size = 8\n",
    "chunks=split_dataframe(X_train,chunk_size)\n",
    "\n",
    "name='shallow'\n",
    "modname ='saved_model/'+therapist+'_'+emotion+'_'+name\n",
    "#model = load_model(modname)\n",
    "model=None\n",
    "epochs=150\n",
    "\n",
    "for chunk in chunks[0:len(chunks)]:\n",
    "    chunk=chunk.drop(columns=['level_0'])\n",
    "    chunk=chunk.reset_index()\n",
    "    try:\n",
    "        train_x, train_y =imgconvert(chunk,l95,DATASET_PATH,img=imgs)       \n",
    "        # Train and Test\n",
    "        train_y=train_y.astype(int)       \n",
    "        # one hot encode outputs\n",
    "        y_train = to_categorical(train_y)        \n",
    "        print(train_x.shape, y_train.shape)\n",
    "        model= mcs.shallow_model( model,therapist.replace(\" \",\"\"), emotion, train_x, y_train, val_x, y_val, train_x.shape[0],  modname, name, epochs  )      \n",
    "      \n",
    "        \n",
    "    except Exception as e:\n",
    "        print(str(e))\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "#from keras.models import load_model\n",
    "#modname ='saved_model/'+therapist+'_'+emotion+'_'+name #+'.h5'\n",
    "#model = load_model(modname)\n",
    "score = model.evaluate(test_x, y_test, verbose=1)\n",
    "\n",
    "#print loss and accuracy\n",
    "print('Test loss:', score[0])\n",
    "print('Test accuracy:', score[1])\n",
    "        \n",
    "    \n",
    "    "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "import os\n",
    "import os\n",
    "print(os.system('!nvidia-smi'))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "import nvidia_smi\n",
    "\n",
    "nvidia_smi.nvmlInit()\n",
    "\n",
    "handle = nvidia_smi.nvmlDeviceGetHandleByIndex(0)\n",
    "# card id 0 hardcoded here, there is also a call to get all available card ids, so we could iterate\n",
    "\n",
    "info = nvidia_smi.nvmlDeviceGetMemoryInfo(handle)\n",
    "\n",
    "print(\"Total memory:\", info.total)\n",
    "print(\"Free memory:\", info.free)\n",
    "print(\"Used memory:\", info.used)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "from numba import cuda \n",
    "device = cuda.get_current_device()\n",
    "device.reset()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "a= arr[0].reshape(416, 64,1)\n",
    "b=arr[1].reshape(416, 64,1)\n",
    "c=arr[2].reshape(416, 64,1)\n",
    "d=tuple([a,b,c])\n",
    "e= np.concatenate(d, axis=2)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "e.shape"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "rgb = np.dstack((abc,abc,abc))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "rgb.shape"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "abc =arr.reshape(44, 416, 1, 64)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "abc.shape"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "arr.shape"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "accelerator": "GPU",
  "colab": {
   "collapsed_sections": [],
   "machine_shape": "hm",
   "name": "usingw2vec.ipynb",
   "provenance": []
  },
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.8.10"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 4
}
