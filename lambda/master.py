# AUTOGENERATED! DO NOT EDIT! File to edit: . (unless otherwise specified).

__all__ = ['parser', 'args', 'therapist', 'emotion', 'name', 'use_existing_model', 'img', 'feat', 't', 'pathG', 'suf',
           'epochs', 'DATASET_PATH0', 'DATASET_PATH4', 'DATASET_PATH8', 'DATASET_PATHS', 'chunk_size', 'height',
           'width', 'modname', 'create_label', 'df', 'df', 'df', 'DATASET_PATH', 'df2', 'lstr', 'x', 'l95', 'getZ',
           'create_arr', 'imgconvert', 'split_dataframe', 'X', 'y', 'val_y', 'test_y', 'y_val', 'y_test', 'chunks',
           'score', 'ts', 'f']

# Cell
# Import the library
import argparse
# Create the parser
parser = argparse.ArgumentParser()
# Add an argument
parser.add_argument('--therapist', type=str, required=True)
parser.add_argument('--emotion', type=str, required=True)
parser.add_argument('--name', type=str, required=True)
parser.add_argument('--IsImage', type=str, required=False, default=1)
parser.add_argument('--featureType', type=str, required=False, default='')
parser.add_argument('--use_existing_model', type=str, required=False, default='no')
parser.add_argument('--duration', type=str, required=False, default=60)
# Parse the argument
args = parser.parse_args()

therapist= args.therapist
emotion=args.emotion
name=args.name
use_existing_model= args.use_existing_model
img=args.IsImage
feat=args.featureType
t=args.duration

# Cell
from tensorflow.tools.docs import doc_controls
import librosa, librosa.display
import matplotlib.pyplot as plt

import os
import glob

import cv2
import pickle5 as pickle
from PIL import Image as im
import argparse
import math
import sys
import time
import copy
import numpy as np

import keras
from keras import regularizers
from keras.models import Sequential, Model
from keras.layers import Dense, Dropout, Flatten, Activation, BatchNormalization #, regularizers
from keras.layers.noise import GaussianNoise
from keras.layers import Conv2D, MaxPooling2D,AveragePooling2D
from keras import backend as K
from keras.callbacks import ModelCheckpoint, EarlyStopping
from keras.utils.np_utils import to_categorical
import tensorflow as tf
import models_custom
from keras.models import load_model
import glob

import os

import pandas as pd
from tensorflow.tools.docs import doc_controls
import librosa, librosa.display
import matplotlib.pyplot as plt

import os
import glob

import cv2
import pickle5 as pickle
from PIL import Image as im
import argparse
import math
import sys
import time
import copy
import numpy as np

import keras
from keras import regularizers
from keras.models import Sequential, Model
from keras.layers import Dense, Dropout, Flatten, Activation, BatchNormalization #, regularizers
from keras.layers.noise import GaussianNoise
from keras.layers import Conv2D, MaxPooling2D,AveragePooling2D
from keras import backend as K
from keras.callbacks import ModelCheckpoint, EarlyStopping
from keras.utils.np_utils import to_categorical
import tensorflow as tf
import models_custom as mcs
from keras.models import load_model
import glob

import os

import pandas as pd
from sklearn.model_selection import train_test_split

# Cell

pathG='../data'
suf=''
if feat=='db1':
    suf='/db1'
elif feat=='lib':
    suf='/lib'
else:
    suf=''
epochs=100
DATASET_PATH0 = pathG+"/w2v2/w2v2L0"+suf
DATASET_PATH4 = pathG+"/w2v2/w2v2L4"+suf
DATASET_PATH8 = pathG+"/w2v2/w2v2L8"+suf
DATASET_PATHS = [DATASET_PATH0,DATASET_PATH4,DATASET_PATH8]

chunk_size = 32

height=224
width=224
modname ='saved_model/'+therapist+'_'+emotion+'_'+name
if use_existing_model=='no':
    model=None
else:
    model = load_model(modname)

#https://stackoverflow.com/questions/10443295/combine-3-separate-numpy-arrays-to-an-rgb-image-in-python

# Cell
def create_label(therapist,emotion,t, balanced=1):
    with open(pathG+'/duration.pickle', 'rb') as f:
            dur=pickle.load(f)

    dur={key:val for key, val in dur.items() if val <= t}
    fls =list(dur.keys())
    def data_balanced (Alemu):
        emt= Alemu[Alemu.emotion==1]
        emtN=Alemu[Alemu.emotion==0]
        sz = np.min([emt.shape[0],emtN.shape[0]])
        Alemu=pd.concat([emt.sample(sz), emtN.sample(sz)])
        return Alemu.sample(frac=1)
    df= pd.read_csv('../data/labelsConsolidated.csv')
    df = df[df['name'].isin(fls)]
    df= df[(df.therapist==therapist) & (df.emotion_type==emotion)]
    df['emotion'] = df['rating'].apply(lambda x: 1 if (x.lower()=="high" or x.lower()=="medium") else 0)
    if balanced==1:
        df=data_balanced (df)
    return df

# Cell

df = create_label(therapist,emotion,t=60, balanced=1)
df = df.reset_index()
df['name2'] =df['name'].apply (lambda x: x.split(".")[0]+".pickle")
df = df.reset_index() # This redundant did that to avoid some errors


# Cell
# This is to delete the rows greater than max size
DATASET_PATH = DATASET_PATHS[0]
#df=df.drop(columns=['level_0'])
df2=df.copy(deep=True)
lstr=[]
for i,row in df.iterrows():
    fl = DATASET_PATH+"/"+row['name2']
    try:
        with open(fl,"rb") as f:
            x=pickle.load(f)
        l1 = x[0].shape[0]
        lstr.append(l1)
        w1 = x[0].shape[1]
        '''
        if l1> l95:
            try:
            #print(i)
                df2=df2.drop(df.iloc[i].name)
            except:
                print(i,l1)
                print("encountered and error")
        '''
    except:
        pass


x=None
l95 =np.max(lstr)

# Cell
import pandas as pd
def getZ(x):
    c=np.array(x[0]).T
    #print(c.shape)
    b = np.max(c)
    a = np.min(c)
    c =(c-a)/(b-a)
    c= pd.DataFrame(c)
    #c= c.astype('float64')
    #print(type(c))
    c=c.describe(percentiles=[.1, .25,.5,.75,.90])
    #print(c.shape)
    c=c.drop(['count'])
    c=np.array(c.T)
    return  c

# Cell
# Normalizing data and creating an array
def create_arr(fl,l95, height,width,img):
    with open(fl,"rb") as f:
        x=pickle.load(f)
    l1 = x[0].shape[0]
    try:
        if type(x) is not np.ndarray:
            x=x.cpu().detach().numpy()
        l95=int(np.ceil(l95/10))*10
        x=np.pad(x, ((0,0), (0,l95-l1), (0, 2)), 'constant')
        height=int(x.shape[1]/10)
        width=int(x.shape[2]/10)
        if img==1:
            c= x[0]
            b = np.max(c)
            a = np.min(c)
            c =255*(c-a)/(b-a)
            c=c.astype(np.uint8)
            data=im.fromarray(c)
            data = data.resize((height,width), im.LANCZOS )
            arr=np.array(data)
            arr = arr.reshape(height,width,1)
            x=None
        else:
            #print("I am here")
            arr=x[0]
            arr = arr.reshape(arr.shape[0],arr.shape[1],1)
            #print(arr.shape)
    except Exception as e: # work on python 2.x
        #print("oops")
        print(str(e))
        arr= None
    return arr


# In[11]:


from os.path import exists
# Converting to image
def imgconvert(df, l95,DATASET_PATH,height, width, img):
    df=df.drop(columns=['level_0'])
    df=df.reset_index()
    arrlist0=[]
    for DATASET_PATH in DATASET_PATHS:
        fl= DATASET_PATH +"/"+df.iloc[0]['name2']
        if exists(fl)==True:
            arrlist0.append(create_arr(fl,l95, height,width,img))
        else:
            print(fl+" Does not exists")
    arr= np.concatenate(tuple(arrlist0), axis=2)
    #arr = arr.reshape(1, height,width,len(DATASET_PATHS))
    arr= np.expand_dims(arr, axis=0)
    #print(arr.shape)
    #fl= DATASET_PATH +"/"+df.iloc[0]['name2']
    #arr=create_arr(fl,l95, height,width,img)

    idx=[]
    for i,row in df.iterrows():
        #fl = DATASET_PATH+"/"+row['name2']
        arrlist2=[]

        for DATASET_PATH in DATASET_PATHS:
            fl = DATASET_PATH+"/"+row['name2']
            if exists(fl)==True:
                arrlist2.append(create_arr(fl,l95, height,width,img))
            else:
                print(fl+" Does not exists")

        try:
            #arr2=create_arr(fl,l95, height,width,img)
            arr2 = np.concatenate(tuple(arrlist2), axis=2)
            #arr2 = arr2.reshape(1, height,width,len(DATASET_PATHS))
            arr2= np.expand_dims(arr2, axis=0)
            arr = np.vstack((arr,arr2))


            idx.append(i)
            x=None
        except Exception as e:
            #print("dhat teri")
            print(str(e))

    arr =np.delete(arr, (0), axis=0) # First row was dummy row
    labels=np.array(df.emotion.iloc[idx])
    return arr , labels
# In[12]:


def split_dataframe(df, chunk_size):
    chunks = list()
    num_chunks = len(df) // chunk_size + 1
    for i in range(num_chunks):
        chunks.append(df[i*chunk_size:(i+1)*chunk_size])
    return chunks



# Cell
X= df
y= df['emotion']
X_train, X_test1, y_train, y_test1 = train_test_split(X, y, test_size=0.6, random_state=42)
X_val, X_test, y_val, y_test = train_test_split(X_test1, y_test1, test_size=0.5, random_state=42)


val_x, val_y =imgconvert(X_val,l95,DATASET_PATHS,height, width, img)
test_x, test_y =imgconvert(X_val,l95,DATASET_PATHS,height, width, img)
val_y=val_y.astype(int)
test_y=test_y.astype(int)
y_val = to_categorical(val_y)
y_test= to_categorical(test_y)


# Cell
import importlib
importlib.reload(models_custom)
chunks=split_dataframe(X_train,chunk_size)

for chunk in chunks[0:len(chunks)]:
    chunk=chunk.drop(columns=['level_0'])
    chunk=chunk.reset_index()
    try:
        train_x, train_y =imgconvert(chunk,l95,DATASET_PATHS,height, width, img)
        train_y=train_y.astype(int)
        # one hot encode outputs
        y_train = to_categorical(train_y)
        print(train_x.shape, y_train.shape)
        therp = therapist.replace(" ","")
        modname ='saved_model/'+therp+'_'+emotion+'_'+name
        if model==None:
            print("Model is None")
            print("Now working on "+ name)
        model, history= models_custom.call_model( use_existing_model,model,therp, emotion, train_x, y_train, val_x, y_val, train_x.shape[0],  modname, name, epochs  )


    except Exception as e:
        print(str(e))



# Cell

score = model.evaluate(test_x, y_test, verbose=1)

#print loss and accuracy
print('Test loss:', score[0])
print('Test accuracy:', score[1])


# Cell
import time

# ts stores the time in seconds
ts = time.time()

f = open("results.txt", "a")
f.write(str(ts)+'|'+therapist+'|'+emotion+'|'+name+'|'+str(score[1])+'\n')
f.close()




# Cell
if __name__ == '__main__':
    pass