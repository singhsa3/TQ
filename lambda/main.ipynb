{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 2,
   "id": "07191bff-49a7-4534-b355-6e4f90b9737d",
   "metadata": {
    "id": "f5351569-b942-48eb-aa96-3491bd07b6f2"
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Collecting pandas==1.4.0\n",
      "  Downloading pandas-1.4.0-cp38-cp38-manylinux_2_17_x86_64.manylinux2014_x86_64.whl (11.7 MB)\n",
      "\u001b[K     |████████████████████████████████| 11.7 MB 20.3 MB/s eta 0:00:01\n",
      "\u001b[?25hCollecting numpy==1.20.0\n",
      "  Downloading numpy-1.20.0-cp38-cp38-manylinux2010_x86_64.whl (15.4 MB)\n",
      "\u001b[K     |████████████████████████████████| 15.4 MB 26.7 MB/s eta 0:00:01\n",
      "\u001b[?25hCollecting pytz>=2020.1\n",
      "  Downloading pytz-2022.1-py2.py3-none-any.whl (503 kB)\n",
      "\u001b[K     |████████████████████████████████| 503 kB 68.9 MB/s eta 0:00:01\n",
      "\u001b[?25hRequirement already satisfied: python-dateutil>=2.8.1 in /home/ubuntu/.local/lib/python3.8/site-packages (from pandas==1.4.0) (2.8.2)\n",
      "Requirement already satisfied: six>=1.5 in /usr/lib/python3/dist-packages (from python-dateutil>=2.8.1->pandas==1.4.0) (1.14.0)\n",
      "Installing collected packages: pytz, numpy, pandas\n",
      "  Attempting uninstall: numpy\n",
      "    Found existing installation: numpy 1.22.4\n",
      "    Uninstalling numpy-1.22.4:\n",
      "      Successfully uninstalled numpy-1.22.4\n",
      "\u001b[33m  WARNING: The scripts f2py, f2py3 and f2py3.8 are installed in '/home/ubuntu/.local/bin' which is not on PATH.\n",
      "  Consider adding this directory to PATH or, if you prefer to suppress this warning, use --no-warn-script-location.\u001b[0m\n",
      "Successfully installed numpy-1.20.0 pandas-1.4.0 pytz-2022.1\n",
      "Collecting keras_self_attention\n",
      "  Downloading keras-self-attention-0.51.0.tar.gz (11 kB)\n",
      "Collecting nbdev\n",
      "  Downloading nbdev-1.2.11-py3-none-any.whl (50 kB)\n",
      "\u001b[K     |████████████████████████████████| 50 kB 7.8 MB/s  eta 0:00:01\n",
      "\u001b[?25hCollecting torchaudio==0.10.1\n",
      "  Downloading torchaudio-0.10.1-cp38-cp38-manylinux1_x86_64.whl (2.9 MB)\n",
      "\u001b[K     |████████████████████████████████| 2.9 MB 38.6 MB/s eta 0:00:01\n",
      "\u001b[?25hCollecting attention\n",
      "  Downloading attention-4.1-py3-none-any.whl (8.6 kB)\n",
      "Requirement already satisfied: pyyaml in /usr/lib/python3/dist-packages (5.3.1)\n",
      "Requirement already satisfied: h5py in /usr/lib/python3/dist-packages (2.10.0)\n",
      "Collecting nvidia_smi\n",
      "  Downloading nvidia_smi-0.1.3-py36-none-any.whl (11 kB)\n",
      "Collecting keras==2.9.0rc1\n",
      "  Downloading keras-2.9.0rc1-py2.py3-none-any.whl (1.6 MB)\n",
      "\u001b[K     |████████████████████████████████| 1.6 MB 95.3 MB/s eta 0:00:01\n",
      "\u001b[?25hRequirement already satisfied: numpy in /home/ubuntu/.local/lib/python3.8/site-packages (from keras_self_attention) (1.20.0)\n",
      "Collecting ghapi\n",
      "  Downloading ghapi-0.1.22-py3-none-any.whl (55 kB)\n",
      "\u001b[K     |████████████████████████████████| 55 kB 5.5 MB/s  eta 0:00:01\n",
      "\u001b[?25hRequirement already satisfied: ipykernel in /usr/lib/python3/dist-packages (from nbdev) (5.2.0)\n",
      "Requirement already satisfied: Jinja2 in /home/ubuntu/.local/lib/python3.8/site-packages (from nbdev) (3.1.2)\n",
      "Collecting fastrelease\n",
      "  Downloading fastrelease-0.1.17-py3-none-any.whl (13 kB)\n",
      "Requirement already satisfied: packaging in /usr/lib/python3/dist-packages (from nbdev) (20.3)\n",
      "Requirement already satisfied: nbconvert>=6.1 in /home/ubuntu/.local/lib/python3.8/site-packages (from nbdev) (6.5.0)\n",
      "Requirement already satisfied: pip in /usr/lib/python3/dist-packages (from nbdev) (20.0.2)\n",
      "Requirement already satisfied: jupyter-client<8 in /home/ubuntu/.local/lib/python3.8/site-packages (from nbdev) (7.3.1)\n",
      "Collecting jupyter\n",
      "  Downloading jupyter-1.0.0-py2.py3-none-any.whl (2.7 kB)\n",
      "Collecting fastcore>=1.4.5\n",
      "  Downloading fastcore-1.5.3-py3-none-any.whl (66 kB)\n",
      "\u001b[K     |████████████████████████████████| 66 kB 6.4 MB/s  eta 0:00:01\n",
      "\u001b[?25hRequirement already satisfied: nbformat>=4.4.0 in /home/ubuntu/.local/lib/python3.8/site-packages (from nbdev) (5.4.0)\n",
      "Collecting torch==1.10.1\n",
      "  Downloading torch-1.10.1-cp38-cp38-manylinux1_x86_64.whl (881.9 MB)\n",
      "\u001b[K     |████████████████▍               | 452.6 MB 110.0 MB/s eta 0:00:04MB/s eta 0:00:49     |████████████████▏               | 447.0 MB 110.0 MB/s eta 0:00:04"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "IOPub data rate exceeded.\n",
      "The Jupyter server will temporarily stop sending output\n",
      "to the client in order to avoid crashing it.\n",
      "To change this limit, set the config variable\n",
      "`--ServerApp.iopub_data_rate_limit`.\n",
      "\n",
      "Current values:\n",
      "ServerApp.iopub_data_rate_limit=1000000.0 (bytes/sec)\n",
      "ServerApp.rate_limit_window=3.0 (secs)\n",
      "\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\u001b[K     |███████████████████████████▊    | 764.0 MB 109.5 MB/s eta 0:00:02"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "IOPub data rate exceeded.\n",
      "The Jupyter server will temporarily stop sending output\n",
      "to the client in order to avoid crashing it.\n",
      "To change this limit, set the config variable\n",
      "`--ServerApp.iopub_data_rate_limit`.\n",
      "\n",
      "Current values:\n",
      "ServerApp.iopub_data_rate_limit=1000000.0 (bytes/sec)\n",
      "ServerApp.rate_limit_window=3.0 (secs)\n",
      "\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\u001b[K     |████████████████████████████████| 881.9 MB 24 kB/s s eta 0:00:01\n",
      "\u001b[?25hCollecting tensorflow>=2.1\n",
      "  Downloading tensorflow-2.9.1-cp38-cp38-manylinux_2_17_x86_64.manylinux2014_x86_64.whl (511.7 MB)\n",
      "\u001b[K     |██████████████████████▊         | 362.5 MB 119.4 MB/s eta 0:00:02                        | 563 kB 90.5 MB/s eta 0:00:06"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "IOPub data rate exceeded.\n",
      "The Jupyter server will temporarily stop sending output\n",
      "to the client in order to avoid crashing it.\n",
      "To change this limit, set the config variable\n",
      "`--ServerApp.iopub_data_rate_limit`.\n",
      "\n",
      "Current values:\n",
      "ServerApp.iopub_data_rate_limit=1000000.0 (bytes/sec)\n",
      "ServerApp.rate_limit_window=3.0 (secs)\n",
      "\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\u001b[K     |████████████████████████████████| 511.7 MB 84 kB/s /s eta 0:00:01\n",
      "\u001b[?25hCollecting sorcery>=0.1.0\n",
      "  Downloading sorcery-0.2.2-py3-none-any.whl (16 kB)\n",
      "Requirement already satisfied: six>=1.12.0 in /usr/lib/python3/dist-packages (from nvidia_smi) (1.14.0)\n",
      "Collecting pytest>=4.3.1\n",
      "  Downloading pytest-7.1.2-py3-none-any.whl (297 kB)\n",
      "\u001b[K     |████████████████████████████████| 297 kB 101.5 MB/s eta 0:00:01\n",
      "\u001b[?25hRequirement already satisfied: MarkupSafe>=2.0 in /home/ubuntu/.local/lib/python3.8/site-packages (from Jinja2->nbdev) (2.1.1)\n",
      "Requirement already satisfied: beautifulsoup4 in /home/ubuntu/.local/lib/python3.8/site-packages (from nbconvert>=6.1->nbdev) (4.11.1)\n",
      "Requirement already satisfied: bleach in /usr/lib/python3/dist-packages (from nbconvert>=6.1->nbdev) (3.1.1)\n",
      "Requirement already satisfied: entrypoints>=0.2.2 in /usr/lib/python3/dist-packages (from nbconvert>=6.1->nbdev) (0.3)\n",
      "Requirement already satisfied: nbclient>=0.5.0 in /home/ubuntu/.local/lib/python3.8/site-packages (from nbconvert>=6.1->nbdev) (0.6.3)\n",
      "Requirement already satisfied: tinycss2 in /home/ubuntu/.local/lib/python3.8/site-packages (from nbconvert>=6.1->nbdev) (1.1.1)\n",
      "Requirement already satisfied: defusedxml in /home/ubuntu/.local/lib/python3.8/site-packages (from nbconvert>=6.1->nbdev) (0.7.1)\n",
      "Requirement already satisfied: pandocfilters>=1.4.1 in /home/ubuntu/.local/lib/python3.8/site-packages (from nbconvert>=6.1->nbdev) (1.5.0)\n",
      "Requirement already satisfied: traitlets>=5.0 in /home/ubuntu/.local/lib/python3.8/site-packages (from nbconvert>=6.1->nbdev) (5.2.1.post0)\n",
      "Requirement already satisfied: mistune<2,>=0.8.1 in /home/ubuntu/.local/lib/python3.8/site-packages (from nbconvert>=6.1->nbdev) (0.8.4)\n",
      "Requirement already satisfied: jupyter-core>=4.7 in /home/ubuntu/.local/lib/python3.8/site-packages (from nbconvert>=6.1->nbdev) (4.10.0)\n",
      "Requirement already satisfied: pygments>=2.4.1 in /home/ubuntu/.local/lib/python3.8/site-packages (from nbconvert>=6.1->nbdev) (2.12.0)\n",
      "Requirement already satisfied: jupyterlab-pygments in /home/ubuntu/.local/lib/python3.8/site-packages (from nbconvert>=6.1->nbdev) (0.2.2)\n",
      "Requirement already satisfied: nest-asyncio>=1.5.4 in /home/ubuntu/.local/lib/python3.8/site-packages (from jupyter-client<8->nbdev) (1.5.5)\n",
      "Requirement already satisfied: tornado>=6.0 in /home/ubuntu/.local/lib/python3.8/site-packages (from jupyter-client<8->nbdev) (6.1)\n",
      "Requirement already satisfied: pyzmq>=22.3 in /home/ubuntu/.local/lib/python3.8/site-packages (from jupyter-client<8->nbdev) (23.0.0)\n",
      "Requirement already satisfied: python-dateutil>=2.8.2 in /home/ubuntu/.local/lib/python3.8/site-packages (from jupyter-client<8->nbdev) (2.8.2)\n",
      "Collecting qtconsole\n",
      "  Downloading qtconsole-5.3.1-py3-none-any.whl (120 kB)\n",
      "\u001b[K     |████████████████████████████████| 120 kB 101.4 MB/s eta 0:00:01\n",
      "\u001b[?25hRequirement already satisfied: notebook in /home/ubuntu/.local/lib/python3.8/site-packages (from jupyter->nbdev) (6.4.11)\n",
      "Requirement already satisfied: ipywidgets in /home/ubuntu/.local/lib/python3.8/site-packages (from jupyter->nbdev) (7.7.0)\n",
      "Requirement already satisfied: jupyter-console in /usr/lib/python3/dist-packages (from jupyter->nbdev) (6.0.0)\n",
      "Requirement already satisfied: fastjsonschema in /home/ubuntu/.local/lib/python3.8/site-packages (from nbformat>=4.4.0->nbdev) (2.15.3)\n",
      "Requirement already satisfied: jsonschema>=2.6 in /usr/lib/python3/dist-packages (from nbformat>=4.4.0->nbdev) (3.2.0)\n",
      "Requirement already satisfied: typing-extensions in /home/ubuntu/.local/lib/python3.8/site-packages (from torch==1.10.1->torchaudio==0.10.1) (4.2.0)\n",
      "Requirement already satisfied: google-pasta>=0.1.1 in /usr/lib/python3/dist-packages (from tensorflow>=2.1->attention) (0.2.0)\n",
      "Requirement already satisfied: wrapt>=1.11.0 in /usr/lib/python3/dist-packages (from tensorflow>=2.1->attention) (1.11.2)\n",
      "Collecting absl-py>=1.0.0\n",
      "  Downloading absl_py-1.1.0-py3-none-any.whl (123 kB)\n",
      "\u001b[K     |████████████████████████████████| 123 kB 48.0 MB/s eta 0:00:01\n",
      "\u001b[?25hRequirement already satisfied: astunparse>=1.6.0 in /usr/lib/python3/dist-packages (from tensorflow>=2.1->attention) (1.6.2)\n",
      "Collecting tensorboard<2.10,>=2.9\n",
      "  Downloading tensorboard-2.9.1-py3-none-any.whl (5.8 MB)\n",
      "\u001b[K     |████████████████████████████████| 5.8 MB 89.1 MB/s eta 0:00:01 |█▌                              | 276 kB 89.1 MB/s eta 0:00:01\n",
      "\u001b[?25hRequirement already satisfied: grpcio<2.0,>=1.24.3 in /usr/lib/python3/dist-packages (from tensorflow>=2.1->attention) (1.29.1)\n",
      "Requirement already satisfied: keras-preprocessing>=1.1.1 in /usr/lib/python3/dist-packages (from tensorflow>=2.1->attention) (1.1.2)\n",
      "Requirement already satisfied: termcolor>=1.1.0 in /usr/lib/python3/dist-packages (from tensorflow>=2.1->attention) (1.1.0)\n",
      "Collecting tensorflow-estimator<2.10.0,>=2.9.0rc0\n",
      "  Downloading tensorflow_estimator-2.9.0-py2.py3-none-any.whl (438 kB)\n",
      "\u001b[K     |████████████████████████████████| 438 kB 87.9 MB/s eta 0:00:01\n",
      "\u001b[?25hRequirement already satisfied: flatbuffers<2,>=1.12 in /usr/lib/python3/dist-packages (from tensorflow>=2.1->attention) (1.12)\n",
      "Requirement already satisfied: protobuf<3.20,>=3.9.2 in /usr/lib/python3/dist-packages (from tensorflow>=2.1->attention) (3.11.4)\n",
      "Requirement already satisfied: setuptools in /usr/lib/python3/dist-packages (from tensorflow>=2.1->attention) (45.2.0)\n",
      "Collecting libclang>=13.0.0\n",
      "  Downloading libclang-14.0.1-py2.py3-none-manylinux1_x86_64.whl (14.5 MB)\n",
      "\u001b[K     |████████████████████████████████| 14.5 MB 81.9 MB/s eta 0:00:01   |█▎                              | 552 kB 81.9 MB/s eta 0:00:01\n",
      "\u001b[?25hCollecting tensorflow-io-gcs-filesystem>=0.23.1\n",
      "  Downloading tensorflow_io_gcs_filesystem-0.26.0-cp38-cp38-manylinux_2_12_x86_64.manylinux2010_x86_64.whl (2.4 MB)\n",
      "\u001b[K     |████████████████████████████████| 2.4 MB 87.5 MB/s eta 0:00:01kB 87.5 MB/s eta 0:00:01\n",
      "\u001b[?25hRequirement already satisfied: gast<=0.4.0,>=0.2.1 in /usr/lib/python3/dist-packages (from tensorflow>=2.1->attention) (0.4.0)\n",
      "Requirement already satisfied: opt-einsum>=2.3.2 in /usr/lib/python3/dist-packages (from tensorflow>=2.1->attention) (3.3.0)\n",
      "Collecting asttokens\n",
      "  Downloading asttokens-2.0.5-py2.py3-none-any.whl (20 kB)\n",
      "Collecting executing\n",
      "  Downloading executing-0.8.3-py2.py3-none-any.whl (16 kB)\n",
      "Collecting littleutils>=0.2.1\n",
      "  Downloading littleutils-0.2.2.tar.gz (6.6 kB)\n",
      "Collecting iniconfig\n",
      "  Downloading iniconfig-1.1.1-py2.py3-none-any.whl (5.0 kB)\n",
      "Collecting py>=1.8.2\n",
      "  Downloading py-1.11.0-py2.py3-none-any.whl (98 kB)\n",
      "\u001b[K     |████████████████████████████████| 98 kB 14.7 MB/s eta 0:00:01\n",
      "\u001b[?25hCollecting pluggy<2.0,>=0.12\n",
      "  Downloading pluggy-1.0.0-py2.py3-none-any.whl (13 kB)\n",
      "Collecting tomli>=1.0.0\n",
      "  Downloading tomli-2.0.1-py3-none-any.whl (12 kB)\n",
      "Requirement already satisfied: attrs>=19.2.0 in /usr/lib/python3/dist-packages (from pytest>=4.3.1->nvidia_smi) (19.3.0)\n",
      "Requirement already satisfied: soupsieve>1.2 in /home/ubuntu/.local/lib/python3.8/site-packages (from beautifulsoup4->nbconvert>=6.1->nbdev) (2.3.2.post1)\n",
      "Requirement already satisfied: webencodings>=0.4 in /usr/lib/python3/dist-packages (from tinycss2->nbconvert>=6.1->nbdev) (0.5.1)\n",
      "Requirement already satisfied: ipython-genutils in /usr/lib/python3/dist-packages (from qtconsole->jupyter->nbdev) (0.2.0)\n",
      "Collecting qtpy>=2.0.1\n",
      "  Downloading QtPy-2.1.0-py3-none-any.whl (68 kB)\n",
      "\u001b[K     |████████████████████████████████| 68 kB 9.2 MB/s  eta 0:00:01\n",
      "\u001b[?25hRequirement already satisfied: Send2Trash>=1.8.0 in /home/ubuntu/.local/lib/python3.8/site-packages (from notebook->jupyter->nbdev) (1.8.0)\n",
      "Requirement already satisfied: terminado>=0.8.3 in /home/ubuntu/.local/lib/python3.8/site-packages (from notebook->jupyter->nbdev) (0.15.0)\n",
      "Requirement already satisfied: prometheus-client in /home/ubuntu/.local/lib/python3.8/site-packages (from notebook->jupyter->nbdev) (0.14.1)\n",
      "Requirement already satisfied: argon2-cffi in /home/ubuntu/.local/lib/python3.8/site-packages (from notebook->jupyter->nbdev) (21.3.0)\n",
      "Requirement already satisfied: ipython>=4.0.0; python_version >= \"3.3\" in /usr/lib/python3/dist-packages (from ipywidgets->jupyter->nbdev) (7.13.0)\n",
      "Requirement already satisfied: widgetsnbextension~=3.6.0 in /home/ubuntu/.local/lib/python3.8/site-packages (from ipywidgets->jupyter->nbdev) (3.6.0)\n",
      "Requirement already satisfied: jupyterlab-widgets>=1.0.0; python_version >= \"3.6\" in /home/ubuntu/.local/lib/python3.8/site-packages (from ipywidgets->jupyter->nbdev) (1.1.0)\n",
      "Collecting tensorboard-plugin-wit>=1.6.0\n",
      "  Downloading tensorboard_plugin_wit-1.8.1-py3-none-any.whl (781 kB)\n",
      "\u001b[K     |████████████████████████████████| 781 kB 57.5 MB/s eta 0:00:01\n",
      "\u001b[?25hCollecting werkzeug>=1.0.1\n",
      "  Downloading Werkzeug-2.1.2-py3-none-any.whl (224 kB)\n",
      "\u001b[K     |████████████████████████████████| 224 kB 92.1 MB/s eta 0:00:01\n",
      "\u001b[?25hRequirement already satisfied: wheel>=0.26 in /usr/lib/python3/dist-packages (from tensorboard<2.10,>=2.9->tensorflow>=2.1->attention) (0.34.2)\n",
      "Requirement already satisfied: markdown>=2.6.8 in /usr/lib/python3/dist-packages (from tensorboard<2.10,>=2.9->tensorflow>=2.1->attention) (3.1.1)\n",
      "Collecting tensorboard-data-server<0.7.0,>=0.6.0\n",
      "  Downloading tensorboard_data_server-0.6.1-py3-none-manylinux2010_x86_64.whl (4.9 MB)\n",
      "\u001b[K     |████████████████████████████████| 4.9 MB 64.1 MB/s eta 0:00:01\n",
      "\u001b[?25hRequirement already satisfied: requests<3,>=2.21.0 in /home/ubuntu/.local/lib/python3.8/site-packages (from tensorboard<2.10,>=2.9->tensorflow>=2.1->attention) (2.27.1)\n",
      "Collecting google-auth<3,>=1.6.3\n",
      "  Downloading google_auth-2.9.0-py2.py3-none-any.whl (167 kB)\n",
      "\u001b[K     |████████████████████████████████| 167 kB 100.3 MB/s eta 0:00:01\n",
      "\u001b[?25hRequirement already satisfied: google-auth-oauthlib<0.5,>=0.4.1 in /usr/lib/python3/dist-packages (from tensorboard<2.10,>=2.9->tensorflow>=2.1->attention) (0.4.1)\n",
      "Requirement already satisfied: ptyprocess; os_name != \"nt\" in /home/ubuntu/.local/lib/python3.8/site-packages (from terminado>=0.8.3->notebook->jupyter->nbdev) (0.7.0)\n",
      "Requirement already satisfied: argon2-cffi-bindings in /home/ubuntu/.local/lib/python3.8/site-packages (from argon2-cffi->notebook->jupyter->nbdev) (21.2.0)\n",
      "Requirement already satisfied: pexpect in /usr/lib/python3/dist-packages (from ipython>=4.0.0; python_version >= \"3.3\"->ipywidgets->jupyter->nbdev) (4.6.0)\n",
      "Requirement already satisfied: certifi>=2017.4.17 in /usr/lib/python3/dist-packages (from requests<3,>=2.21.0->tensorboard<2.10,>=2.9->tensorflow>=2.1->attention) (2019.11.28)\n",
      "Requirement already satisfied: charset-normalizer~=2.0.0; python_version >= \"3\" in /home/ubuntu/.local/lib/python3.8/site-packages (from requests<3,>=2.21.0->tensorboard<2.10,>=2.9->tensorflow>=2.1->attention) (2.0.12)\n",
      "Requirement already satisfied: urllib3<1.27,>=1.21.1 in /usr/lib/python3/dist-packages (from requests<3,>=2.21.0->tensorboard<2.10,>=2.9->tensorflow>=2.1->attention) (1.25.8)\n",
      "Requirement already satisfied: idna<4,>=2.5; python_version >= \"3\" in /usr/lib/python3/dist-packages (from requests<3,>=2.21.0->tensorboard<2.10,>=2.9->tensorflow>=2.1->attention) (2.8)\n",
      "Requirement already satisfied: rsa<5,>=3.1.4; python_version >= \"3.6\" in /usr/lib/python3/dist-packages (from google-auth<3,>=1.6.3->tensorboard<2.10,>=2.9->tensorflow>=2.1->attention) (4.0)\n",
      "Requirement already satisfied: pyasn1-modules>=0.2.1 in /usr/lib/python3/dist-packages (from google-auth<3,>=1.6.3->tensorboard<2.10,>=2.9->tensorflow>=2.1->attention) (0.2.1)\n",
      "Requirement already satisfied: cachetools<6.0,>=2.0.0 in /usr/lib/python3/dist-packages (from google-auth<3,>=1.6.3->tensorboard<2.10,>=2.9->tensorflow>=2.1->attention) (4.0.0)\n",
      "Requirement already satisfied: cffi>=1.0.1 in /home/ubuntu/.local/lib/python3.8/site-packages (from argon2-cffi-bindings->argon2-cffi->notebook->jupyter->nbdev) (1.15.0)\n",
      "Requirement already satisfied: pycparser in /home/ubuntu/.local/lib/python3.8/site-packages (from cffi>=1.0.1->argon2-cffi-bindings->argon2-cffi->notebook->jupyter->nbdev) (2.21)\n",
      "Building wheels for collected packages: keras-self-attention, littleutils\n",
      "  Building wheel for keras-self-attention (setup.py) ... \u001b[?25ldone\n",
      "\u001b[?25h  Created wheel for keras-self-attention: filename=keras_self_attention-0.51.0-py3-none-any.whl size=18913 sha256=51c86149c4d81e57affba4614dda8e6739d8829f143a72813a1de7c185257a72\n",
      "  Stored in directory: /home/ubuntu/.cache/pip/wheels/ac/13/2d/3de7c76f618a8d162884ac5b726a8c2242ad88afa370f1e62f\n",
      "  Building wheel for littleutils (setup.py) ... \u001b[?25ldone\n",
      "\u001b[?25h  Created wheel for littleutils: filename=littleutils-0.2.2-py3-none-any.whl size=7048 sha256=cf0fe9f53b16a73813d91e9a3a6e0984d7b8346d3fce97c6242f24066cda500b\n",
      "  Stored in directory: /home/ubuntu/.cache/pip/wheels/6a/33/c4/0ef84d7f5568c2823e3d63a6e08988852fb9e4bc822034870a\n",
      "Successfully built keras-self-attention littleutils\n",
      "Installing collected packages: keras-self-attention, fastcore, ghapi, fastrelease, qtpy, qtconsole, jupyter, nbdev, torch, torchaudio, absl-py, tensorboard-plugin-wit, werkzeug, tensorboard-data-server, google-auth, tensorboard, tensorflow-estimator, keras, libclang, tensorflow-io-gcs-filesystem, tensorflow, attention, asttokens, executing, littleutils, sorcery, iniconfig, py, pluggy, tomli, pytest, nvidia-smi\n",
      "\u001b[33m  WARNING: The scripts completion-ghapi, gh-create-workflow, ghapi, ghpath and ghraw are installed in '/home/ubuntu/.local/bin' which is not on PATH.\n",
      "  Consider adding this directory to PATH or, if you prefer to suppress this warning, use --no-warn-script-location.\u001b[0m\n",
      "\u001b[33m  WARNING: The scripts fastrelease, fastrelease_bump_version, fastrelease_changelog, fastrelease_conda_package and fastrelease_release are installed in '/home/ubuntu/.local/bin' which is not on PATH.\n",
      "  Consider adding this directory to PATH or, if you prefer to suppress this warning, use --no-warn-script-location.\u001b[0m\n",
      "\u001b[33m  WARNING: The script qtpy is installed in '/home/ubuntu/.local/bin' which is not on PATH.\n",
      "  Consider adding this directory to PATH or, if you prefer to suppress this warning, use --no-warn-script-location.\u001b[0m\n",
      "\u001b[33m  WARNING: The scripts nbdev_build_docs, nbdev_build_lib, nbdev_bump_version, nbdev_clean_nbs, nbdev_detach, nbdev_diff_nbs, nbdev_fix_merge, nbdev_install_git_hooks, nbdev_nb2md, nbdev_new, nbdev_read_nbs, nbdev_test_nbs, nbdev_trust_nbs and nbdev_update_lib are installed in '/home/ubuntu/.local/bin' which is not on PATH.\n",
      "  Consider adding this directory to PATH or, if you prefer to suppress this warning, use --no-warn-script-location.\u001b[0m\n",
      "\u001b[33m  WARNING: The scripts convert-caffe2-to-onnx, convert-onnx-to-caffe2 and torchrun are installed in '/home/ubuntu/.local/bin' which is not on PATH.\n",
      "  Consider adding this directory to PATH or, if you prefer to suppress this warning, use --no-warn-script-location.\u001b[0m\n",
      "\u001b[33m  WARNING: The script tensorboard is installed in '/home/ubuntu/.local/bin' which is not on PATH.\n",
      "  Consider adding this directory to PATH or, if you prefer to suppress this warning, use --no-warn-script-location.\u001b[0m\n",
      "\u001b[33m  WARNING: The scripts estimator_ckpt_converter, import_pb_to_tensorboard, saved_model_cli, tensorboard, tf_upgrade_v2, tflite_convert, toco and toco_from_protos are installed in '/home/ubuntu/.local/bin' which is not on PATH.\n",
      "  Consider adding this directory to PATH or, if you prefer to suppress this warning, use --no-warn-script-location.\u001b[0m\n",
      "\u001b[33m  WARNING: The scripts py.test and pytest are installed in '/home/ubuntu/.local/bin' which is not on PATH.\n",
      "  Consider adding this directory to PATH or, if you prefer to suppress this warning, use --no-warn-script-location.\u001b[0m\n",
      "Successfully installed absl-py-1.1.0 asttokens-2.0.5 attention-4.1 executing-0.8.3 fastcore-1.5.3 fastrelease-0.1.17 ghapi-0.1.22 google-auth-2.9.0 iniconfig-1.1.1 jupyter-1.0.0 keras-2.9.0rc1 keras-self-attention-0.51.0 libclang-14.0.1 littleutils-0.2.2 nbdev-1.2.11 nvidia-smi-0.1.3 pluggy-1.0.0 py-1.11.0 pytest-7.1.2 qtconsole-5.3.1 qtpy-2.1.0 sorcery-0.2.2 tensorboard-2.9.1 tensorboard-data-server-0.6.1 tensorboard-plugin-wit-1.8.1 tensorflow-2.9.1 tensorflow-estimator-2.9.0 tensorflow-io-gcs-filesystem-0.26.0 tomli-2.0.1 torch-1.10.1 torchaudio-0.10.1 werkzeug-2.1.2\n",
      "Requirement already satisfied: tensorflow in /home/ubuntu/.local/lib/python3.8/site-packages (2.9.1)\n",
      "Collecting librosa\n",
      "  Downloading librosa-0.9.2-py3-none-any.whl (214 kB)\n",
      "\u001b[K     |████████████████████████████████| 214 kB 27.3 MB/s eta 0:00:01\n",
      "\u001b[?25hRequirement already satisfied: matplotlib in /home/ubuntu/.local/lib/python3.8/site-packages (3.5.2)\n",
      "Collecting pickle5\n",
      "  Downloading pickle5-0.0.11.tar.gz (132 kB)\n",
      "\u001b[K     |████████████████████████████████| 132 kB 64.4 MB/s eta 0:00:01\n",
      "\u001b[?25hRequirement already satisfied: Pillow in /usr/lib/python3/dist-packages (7.0.0)\n",
      "Collecting opencv-python\n",
      "  Downloading opencv_python-4.6.0.66-cp36-abi3-manylinux_2_17_x86_64.manylinux2014_x86_64.whl (60.9 MB)\n",
      "\u001b[K     |████████████████████████████████| 60.9 MB 44.2 MB/s eta 0:00:01\n",
      "\u001b[?25hCollecting numba\n",
      "  Downloading numba-0.55.2-cp38-cp38-manylinux2014_x86_64.manylinux_2_17_x86_64.whl (3.4 MB)\n",
      "\u001b[K     |████████████████████████████████| 3.4 MB 90.8 MB/s eta 0:00:01\n",
      "\u001b[?25hRequirement already satisfied: setuptools in /usr/lib/python3/dist-packages (from tensorflow) (45.2.0)\n",
      "Requirement already satisfied: keras-preprocessing>=1.1.1 in /usr/lib/python3/dist-packages (from tensorflow) (1.1.2)\n",
      "Requirement already satisfied: opt-einsum>=2.3.2 in /usr/lib/python3/dist-packages (from tensorflow) (3.3.0)\n",
      "Requirement already satisfied: termcolor>=1.1.0 in /usr/lib/python3/dist-packages (from tensorflow) (1.1.0)\n",
      "Requirement already satisfied: keras<2.10.0,>=2.9.0rc0 in /home/ubuntu/.local/lib/python3.8/site-packages (from tensorflow) (2.9.0rc1)\n",
      "Requirement already satisfied: six>=1.12.0 in /usr/lib/python3/dist-packages (from tensorflow) (1.14.0)\n",
      "Requirement already satisfied: grpcio<2.0,>=1.24.3 in /usr/lib/python3/dist-packages (from tensorflow) (1.29.1)\n",
      "Requirement already satisfied: flatbuffers<2,>=1.12 in /usr/lib/python3/dist-packages (from tensorflow) (1.12)\n",
      "Requirement already satisfied: absl-py>=1.0.0 in /home/ubuntu/.local/lib/python3.8/site-packages (from tensorflow) (1.1.0)\n",
      "Requirement already satisfied: h5py>=2.9.0 in /usr/lib/python3/dist-packages (from tensorflow) (2.10.0)\n",
      "Requirement already satisfied: astunparse>=1.6.0 in /usr/lib/python3/dist-packages (from tensorflow) (1.6.2)\n",
      "Requirement already satisfied: wrapt>=1.11.0 in /usr/lib/python3/dist-packages (from tensorflow) (1.11.2)\n",
      "Requirement already satisfied: typing-extensions>=3.6.6 in /home/ubuntu/.local/lib/python3.8/site-packages (from tensorflow) (4.2.0)\n",
      "Requirement already satisfied: gast<=0.4.0,>=0.2.1 in /usr/lib/python3/dist-packages (from tensorflow) (0.4.0)\n",
      "Requirement already satisfied: packaging in /usr/lib/python3/dist-packages (from tensorflow) (20.3)\n",
      "Requirement already satisfied: protobuf<3.20,>=3.9.2 in /usr/lib/python3/dist-packages (from tensorflow) (3.11.4)\n",
      "Requirement already satisfied: google-pasta>=0.1.1 in /usr/lib/python3/dist-packages (from tensorflow) (0.2.0)\n",
      "Requirement already satisfied: libclang>=13.0.0 in /home/ubuntu/.local/lib/python3.8/site-packages (from tensorflow) (14.0.1)\n",
      "Requirement already satisfied: numpy>=1.20 in /home/ubuntu/.local/lib/python3.8/site-packages (from tensorflow) (1.20.0)\n",
      "Requirement already satisfied: tensorboard<2.10,>=2.9 in /home/ubuntu/.local/lib/python3.8/site-packages (from tensorflow) (2.9.1)\n",
      "Requirement already satisfied: tensorflow-io-gcs-filesystem>=0.23.1 in /home/ubuntu/.local/lib/python3.8/site-packages (from tensorflow) (0.26.0)\n",
      "Requirement already satisfied: tensorflow-estimator<2.10.0,>=2.9.0rc0 in /home/ubuntu/.local/lib/python3.8/site-packages (from tensorflow) (2.9.0)\n",
      "Requirement already satisfied: scikit-learn>=0.19.1 in /usr/lib/python3/dist-packages (from librosa) (0.22.2.post1)\n",
      "Requirement already satisfied: decorator>=4.0.10 in /usr/lib/python3/dist-packages (from librosa) (4.4.2)\n",
      "Requirement already satisfied: joblib>=0.14 in /home/ubuntu/.local/lib/python3.8/site-packages (from librosa) (1.1.0)\n",
      "Collecting audioread>=2.1.9\n",
      "  Downloading audioread-2.1.9.tar.gz (377 kB)\n",
      "\u001b[K     |████████████████████████████████| 377 kB 67.0 MB/s eta 0:00:01\n",
      "\u001b[?25hCollecting resampy>=0.2.2\n",
      "  Downloading resampy-0.3.1-py3-none-any.whl (3.1 MB)\n",
      "\u001b[K     |████████████████████████████████| 3.1 MB 60.4 MB/s eta 0:00:01\n",
      "\u001b[?25hRequirement already satisfied: scipy>=1.2.0 in /home/ubuntu/.local/lib/python3.8/site-packages (from librosa) (1.8.1)\n",
      "Collecting pooch>=1.0\n",
      "  Downloading pooch-1.6.0-py3-none-any.whl (56 kB)\n",
      "\u001b[K     |████████████████████████████████| 56 kB 7.8 MB/s  eta 0:00:01\n",
      "\u001b[?25hCollecting soundfile>=0.10.2\n",
      "  Downloading SoundFile-0.10.3.post1-py2.py3-none-any.whl (21 kB)\n",
      "Requirement already satisfied: python-dateutil>=2.7 in /home/ubuntu/.local/lib/python3.8/site-packages (from matplotlib) (2.8.2)\n",
      "Requirement already satisfied: cycler>=0.10 in /usr/lib/python3/dist-packages (from matplotlib) (0.10.0)\n",
      "Requirement already satisfied: kiwisolver>=1.0.1 in /usr/lib/python3/dist-packages (from matplotlib) (1.0.1)\n",
      "Requirement already satisfied: fonttools>=4.22.0 in /home/ubuntu/.local/lib/python3.8/site-packages (from matplotlib) (4.33.3)\n",
      "Requirement already satisfied: pyparsing>=2.2.1 in /usr/lib/python3/dist-packages (from matplotlib) (2.4.6)\n",
      "Collecting llvmlite<0.39,>=0.38.0rc1\n",
      "  Downloading llvmlite-0.38.1-cp38-cp38-manylinux_2_17_x86_64.manylinux2014_x86_64.whl (34.5 MB)\n",
      "\u001b[K     |████████████████████████████████| 34.5 MB 42.4 MB/s eta 0:00:01\n",
      "\u001b[?25hRequirement already satisfied: requests<3,>=2.21.0 in /home/ubuntu/.local/lib/python3.8/site-packages (from tensorboard<2.10,>=2.9->tensorflow) (2.27.1)\n",
      "Requirement already satisfied: werkzeug>=1.0.1 in /home/ubuntu/.local/lib/python3.8/site-packages (from tensorboard<2.10,>=2.9->tensorflow) (2.1.2)\n",
      "Requirement already satisfied: wheel>=0.26 in /usr/lib/python3/dist-packages (from tensorboard<2.10,>=2.9->tensorflow) (0.34.2)\n",
      "Requirement already satisfied: google-auth<3,>=1.6.3 in /home/ubuntu/.local/lib/python3.8/site-packages (from tensorboard<2.10,>=2.9->tensorflow) (2.9.0)\n",
      "Requirement already satisfied: markdown>=2.6.8 in /usr/lib/python3/dist-packages (from tensorboard<2.10,>=2.9->tensorflow) (3.1.1)\n",
      "Requirement already satisfied: tensorboard-plugin-wit>=1.6.0 in /home/ubuntu/.local/lib/python3.8/site-packages (from tensorboard<2.10,>=2.9->tensorflow) (1.8.1)\n",
      "Requirement already satisfied: tensorboard-data-server<0.7.0,>=0.6.0 in /home/ubuntu/.local/lib/python3.8/site-packages (from tensorboard<2.10,>=2.9->tensorflow) (0.6.1)\n",
      "Requirement already satisfied: google-auth-oauthlib<0.5,>=0.4.1 in /usr/lib/python3/dist-packages (from tensorboard<2.10,>=2.9->tensorflow) (0.4.1)\n",
      "Requirement already satisfied: appdirs>=1.3.0 in /usr/lib/python3/dist-packages (from pooch>=1.0->librosa) (1.4.3)\n",
      "Requirement already satisfied: cffi>=1.0 in /home/ubuntu/.local/lib/python3.8/site-packages (from soundfile>=0.10.2->librosa) (1.15.0)\n",
      "Requirement already satisfied: idna<4,>=2.5; python_version >= \"3\" in /usr/lib/python3/dist-packages (from requests<3,>=2.21.0->tensorboard<2.10,>=2.9->tensorflow) (2.8)\n",
      "Requirement already satisfied: charset-normalizer~=2.0.0; python_version >= \"3\" in /home/ubuntu/.local/lib/python3.8/site-packages (from requests<3,>=2.21.0->tensorboard<2.10,>=2.9->tensorflow) (2.0.12)\n",
      "Requirement already satisfied: certifi>=2017.4.17 in /usr/lib/python3/dist-packages (from requests<3,>=2.21.0->tensorboard<2.10,>=2.9->tensorflow) (2019.11.28)\n",
      "Requirement already satisfied: urllib3<1.27,>=1.21.1 in /usr/lib/python3/dist-packages (from requests<3,>=2.21.0->tensorboard<2.10,>=2.9->tensorflow) (1.25.8)\n",
      "Requirement already satisfied: cachetools<6.0,>=2.0.0 in /usr/lib/python3/dist-packages (from google-auth<3,>=1.6.3->tensorboard<2.10,>=2.9->tensorflow) (4.0.0)\n",
      "Requirement already satisfied: pyasn1-modules>=0.2.1 in /usr/lib/python3/dist-packages (from google-auth<3,>=1.6.3->tensorboard<2.10,>=2.9->tensorflow) (0.2.1)\n",
      "Requirement already satisfied: rsa<5,>=3.1.4; python_version >= \"3.6\" in /usr/lib/python3/dist-packages (from google-auth<3,>=1.6.3->tensorboard<2.10,>=2.9->tensorflow) (4.0)\n",
      "Requirement already satisfied: pycparser in /home/ubuntu/.local/lib/python3.8/site-packages (from cffi>=1.0->soundfile>=0.10.2->librosa) (2.21)\n",
      "Building wheels for collected packages: pickle5, audioread\n",
      "  Building wheel for pickle5 (setup.py) ... \u001b[?25ldone\n",
      "\u001b[?25h  Created wheel for pickle5: filename=pickle5-0.0.11-cp38-cp38-linux_x86_64.whl size=262082 sha256=78af319b360fa29648e7886f259c8c085d5c9ae4521e3e531a1d16d8b3bb3e97\n",
      "  Stored in directory: /home/ubuntu/.cache/pip/wheels/25/d4/61/dbd8edd1a0d656be7b4267c85db3b61951eb60016a0154a122\n",
      "  Building wheel for audioread (setup.py) ... \u001b[?25ldone\n",
      "\u001b[?25h  Created wheel for audioread: filename=audioread-2.1.9-py3-none-any.whl size=23142 sha256=cafdf6aef9eedd7a0d7d1d73840288e0dd91c92d5cfe344aefebd2a2db2d6f0c\n",
      "  Stored in directory: /home/ubuntu/.cache/pip/wheels/49/5a/e4/df590783499a992a88de6c0898991d1167453a3196d0d1eeb7\n",
      "Successfully built pickle5 audioread\n",
      "Installing collected packages: audioread, llvmlite, numba, resampy, pooch, soundfile, librosa, pickle5, opencv-python\n",
      "Successfully installed audioread-2.1.9 librosa-0.9.2 llvmlite-0.38.1 numba-0.55.2 opencv-python-4.6.0.66 pickle5-0.0.11 pooch-1.6.0 resampy-0.3.1 soundfile-0.10.3.post1\n"
     ]
    }
   ],
   "source": [
    "!pip install  pandas==1.4.0 numpy==1.20.0\n",
    "!pip install keras_self_attention nbdev torchaudio==0.10.1 attention pyyaml h5py nvidia_smi keras==2.9.0rc1 \n",
    "!pip install tensorflow librosa matplotlib pickle5 Pillow opencv-python numba "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "32f2919a-7a0a-4137-8aeb-c03882e30667",
   "metadata": {
    "id": "32f2919a-7a0a-4137-8aeb-c03882e30667"
   },
   "outputs": [],
   "source": [
    "#default_exp master"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "0eb26169-19c8-429e-a5ae-253c0f6f141a",
   "metadata": {
    "id": "ac7f51d4-0922-4ff9-9527-f418593b698a"
   },
   "outputs": [],
   "source": [
    "#export\n",
    "# Import the library\n",
    "import argparse\n",
    "# Create the parser\n",
    "parser = argparse.ArgumentParser()\n",
    "# Add an argument\n",
    "parser.add_argument('--therapist', type=str, required=True)\n",
    "parser.add_argument('--emotion', type=str, required=True)\n",
    "parser.add_argument('--name', type=str, required=True)\n",
    "\n",
    "parser.add_argument('--use_existing_model', type=str, required=False, default='no')\n",
    "\n",
    "# Parse the argument\n",
    "args = parser.parse_args()\n",
    "\n",
    "therapist= args.therapist\n",
    "emotion=args.emotion\n",
    "name=args.name\n",
    "use_existing_model= args.use_existing_model\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "id": "853ab06e-100e-471d-9f11-39e236a3c7c5",
   "metadata": {
    "id": "853ab06e-100e-471d-9f11-39e236a3c7c5"
   },
   "outputs": [
    {
     "ename": "ModuleNotFoundError",
     "evalue": "No module named 'librosa'",
     "output_type": "error",
     "traceback": [
      "\u001b[0;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[0;31mModuleNotFoundError\u001b[0m                       Traceback (most recent call last)",
      "\u001b[0;32m<ipython-input-1-4bd76708cc8f>\u001b[0m in \u001b[0;36m<module>\u001b[0;34m\u001b[0m\n\u001b[1;32m      1\u001b[0m \u001b[0;31m#export\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m      2\u001b[0m \u001b[0;32mfrom\u001b[0m \u001b[0mtensorflow\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mtools\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mdocs\u001b[0m \u001b[0;32mimport\u001b[0m \u001b[0mdoc_controls\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m----> 3\u001b[0;31m \u001b[0;32mimport\u001b[0m \u001b[0mlibrosa\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mlibrosa\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mdisplay\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m      4\u001b[0m \u001b[0;32mimport\u001b[0m \u001b[0mmatplotlib\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mpyplot\u001b[0m \u001b[0;32mas\u001b[0m \u001b[0mplt\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m      5\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;31mModuleNotFoundError\u001b[0m: No module named 'librosa'"
     ]
    }
   ],
   "source": [
    "#export\n",
    "from tensorflow.tools.docs import doc_controls\n",
    "import librosa, librosa.display\n",
    "import matplotlib.pyplot as plt\n",
    "\n",
    "import os\n",
    "import glob\n",
    "\n",
    "import cv2\n",
    "import pickle5 as pickle\n",
    "from PIL import Image as im\n",
    "import argparse\n",
    "import math\n",
    "import sys\n",
    "import time\n",
    "import copy\n",
    "import numpy as np\n",
    "\n",
    "import keras\n",
    "from keras import regularizers\n",
    "from keras.models import Sequential, Model\n",
    "from keras.layers import Dense, Dropout, Flatten, Activation, BatchNormalization #, regularizers\n",
    "from keras.layers.noise import GaussianNoise\n",
    "from keras.layers import Conv2D, MaxPooling2D,AveragePooling2D\n",
    "from keras import backend as K\n",
    "from keras.callbacks import ModelCheckpoint, EarlyStopping\n",
    "from keras.utils.np_utils import to_categorical\n",
    "import tensorflow as tf\n",
    "import models_custom \n",
    "from keras.models import load_model\n",
    "import glob\n",
    "\n",
    "import os\n",
    "\n",
    "import pandas as pd\n",
    "from tensorflow.tools.docs import doc_controls\n",
    "import librosa, librosa.display\n",
    "import matplotlib.pyplot as plt\n",
    "\n",
    "import os\n",
    "import glob\n",
    "\n",
    "import cv2\n",
    "import pickle5 as pickle\n",
    "from PIL import Image as im\n",
    "import argparse\n",
    "import math\n",
    "import sys\n",
    "import time\n",
    "import copy\n",
    "import numpy as np\n",
    "\n",
    "import keras\n",
    "from keras import regularizers\n",
    "from keras.models import Sequential, Model\n",
    "from keras.layers import Dense, Dropout, Flatten, Activation, BatchNormalization #, regularizers\n",
    "from keras.layers.noise import GaussianNoise\n",
    "from keras.layers import Conv2D, MaxPooling2D,AveragePooling2D\n",
    "from keras import backend as K\n",
    "from keras.callbacks import ModelCheckpoint, EarlyStopping\n",
    "from keras.utils.np_utils import to_categorical\n",
    "import tensorflow as tf\n",
    "import models_custom as mcs\n",
    "from keras.models import load_model\n",
    "import glob\n",
    "\n",
    "import os\n",
    "\n",
    "import pandas as pd\n",
    "from sklearn.model_selection import train_test_split"
   ]
  },
  {
   "cell_type": "raw",
   "id": "d1106a12-1f54-49d2-a66d-05d24acb6533",
   "metadata": {
    "id": "d1106a12-1f54-49d2-a66d-05d24acb6533"
   },
   "source": [
    "--therapist 'Yared Alemu' --emotion 'fear' --name '3CNN2LSTM_Attn' --duration 45 --featureType 'db1' --IsImage 0\n",
    "\n",
    "            elif name=='conv1dlstmAttn'\n",
    "                model=create_conv1dlstmAttn( img_rows, img_cols, filters)\n",
    "            elif name=='LSTM_Attn':\n",
    "                model=create_LSTM_Attn( img_rows, img_cols, filters)\n",
    "            else:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "c4b36dad-0268-44e7-85bc-e93c660ea201",
   "metadata": {
    "id": "c4b36dad-0268-44e7-85bc-e93c660ea201"
   },
   "outputs": [],
   "source": [
    "therapist='Yared Alemu'\n",
    "emotion='anger'\n",
    "name='conv1dlstmAttn' #'LSTM_Attn' #'conv1dlstmAttn', #'shallow' #'3CNN2LSTM_Attn' #'conv1dlstmAttn' #'LSTM_Attn' #'3CNN2LSTM_Attn' #'shallow'\n",
    "use_existing_model= 'no'\n",
    "t=30\n",
    "feat=''\n",
    "img=0"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "0c4f6493-98d2-4cf1-84dd-ea284dc48df8",
   "metadata": {},
   "outputs": [],
   "source": [
    "#export\n",
    "X= df\n",
    "y= df['emotion']\n",
    "X_train, X_test1, y_train, y_test1 = train_test_split(X, y, test_size=0.2, random_state=42)\n",
    "X_val, X_test, y_val, y_test = train_test_split(X_test1, y_test1, test_size=0.5, random_state=42)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "42d2ec59-18c7-4dba-957c-8e52ad641216",
   "metadata": {},
   "outputs": [],
   "source": [
    "X_train.head()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "76907dec-f041-42ec-89a7-12f433c3fc2d",
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/",
     "height": 53
    },
    "executionInfo": {
     "elapsed": 44,
     "status": "ok",
     "timestamp": 1657130227109,
     "user": {
      "displayName": "Sanjeev Singh Kenwar",
      "userId": "00714071671360104547"
     },
     "user_tz": 240
    },
    "id": "76907dec-f041-42ec-89a7-12f433c3fc2d",
    "outputId": "d1118030-1bfd-46ae-b36c-8c8d564f87d2"
   },
   "outputs": [],
   "source": [
    "print(val_x.shape)\n",
    "name\n",
    "#use_existing_model"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "ea4c2537-04dd-46d8-a02a-6c94d253b6e1",
   "metadata": {
    "id": "ea4c2537-04dd-46d8-a02a-6c94d253b6e1"
   },
   "outputs": [],
   "source": [
    "model=None\n",
    "use_existing_model='no'"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "0a595188-b4ca-4780-ac8d-68322f109e17",
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/"
    },
    "id": "0a595188-b4ca-4780-ac8d-68322f109e17",
    "outputId": "88392324-59ac-4961-f111-7fc2812b080b"
   },
   "outputs": [],
   "source": [
    "#export\n",
    "import importlib\n",
    "importlib.reload(models_custom)\n",
    "chunks=split_dataframe(X_train,chunk_size)\n",
    "\n",
    "for chunk in chunks[0:len(chunks)]:\n",
    "    chunk=chunk.drop(columns=['level_0'])\n",
    "    chunk=chunk.reset_index()\n",
    "    try:\n",
    "        '''\n",
    "        train_x, train_y =imgconvert(chunk,l95,DATASET_PATHS,height, width, img)\n",
    "        train_y=train_y.astype(int)       \n",
    "        # one hot encode outputs\n",
    "        y_train = to_categorical(train_y) \n",
    "        '''\n",
    "        train_x, y_train = getarr(chunk)\n",
    "        print(train_x.shape, y_train.shape)\n",
    "        therp = therapist.replace(\" \",\"\")\n",
    "        modname ='saved_model/'+therp+'_'+emotion+'_'+name\n",
    "        if model==None:\n",
    "            print(\"Model is None\")\n",
    "            print(\"Now working on \"+ name)\n",
    "        model, history= models_custom.call_model( use_existing_model,model,therp, emotion, train_x, y_train, val_x, y_val, train_x.shape[0],  modname, name, epochs  )      \n",
    "      \n",
    "        \n",
    "    except Exception as e:\n",
    "        print(str(e))\n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "8243445f-b11a-4b64-b434-6a7be6c3a406",
   "metadata": {
    "id": "8243445f-b11a-4b64-b434-6a7be6c3a406"
   },
   "outputs": [],
   "source": [
    "#export\n",
    "\n",
    "score = model.evaluate(test_x, y_test, verbose=1)\n",
    "\n",
    "#print loss and accuracy\n",
    "print('Test loss:', score[0])\n",
    "print('Test accuracy:', score[1])\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "6e029591-b134-4470-ad36-611de7d06042",
   "metadata": {
    "id": "6e029591-b134-4470-ad36-611de7d06042"
   },
   "outputs": [],
   "source": [
    "preds= model.predict(test_x)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "e5538d01-bf28-4b3b-9be7-ac67ac3b2633",
   "metadata": {
    "id": "e5538d01-bf28-4b3b-9be7-ac67ac3b2633"
   },
   "outputs": [],
   "source": [
    "b= np.where(preds > .5, 1, 0)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "54f4d688-32f2-49ec-9a6f-696c74dbb0b0",
   "metadata": {
    "id": "54f4d688-32f2-49ec-9a6f-696c74dbb0b0"
   },
   "outputs": [],
   "source": [
    "153/232"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "5f838549-9e6f-488f-b254-708cf4b49f36",
   "metadata": {
    "id": "5f838549-9e6f-488f-b254-708cf4b49f36"
   },
   "outputs": [],
   "source": [
    "y_test.sum(axis=0)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "ad3b8aee-1b97-4ace-a3b4-d645e0055b82",
   "metadata": {
    "id": "ad3b8aee-1b97-4ace-a3b4-d645e0055b82"
   },
   "outputs": [],
   "source": [
    "from sklearn.metrics import confusion_matrix\n",
    "\n",
    "\n",
    "\n",
    "conf_mat = confusion_matrix(y_test, model.predict(test_x))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "7cb977c6-fe78-4909-9f64-33b25c5a4a98",
   "metadata": {
    "id": "7cb977c6-fe78-4909-9f64-33b25c5a4a98"
   },
   "outputs": [],
   "source": [
    "#export\n",
    "import time\n",
    "  \n",
    "# ts stores the time in seconds\n",
    "ts = time.time()\n",
    "\n",
    "f = open(\"results.txt\", \"a\")\n",
    "f.write(str(ts)+'|'+therapist+'|'+emotion+'|'+name+'|'+str(score[1])+'\\n')\n",
    "f.close()\n",
    "\n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "586fc0db-808d-4376-b912-58aad20a0058",
   "metadata": {
    "id": "586fc0db-808d-4376-b912-58aad20a0058"
   },
   "outputs": [],
   "source": [
    "#nbdev_build_lib --fname master.ipynb\n",
    "#python master.py --therapist 'Yared Alemu' --emotion 'fear' --name '3CNN2LSTM_Attn'"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "4c2b7008-984b-412e-b40d-cd2ac5e7ff6e",
   "metadata": {
    "id": "4c2b7008-984b-412e-b40d-cd2ac5e7ff6e"
   },
   "outputs": [],
   "source": [
    "from numba import cuda \n",
    "device = cuda.get_current_device()\n",
    "device.reset()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "a01ba09c-ebf6-4b8c-9701-ea0c08d317fd",
   "metadata": {
    "id": "a01ba09c-ebf6-4b8c-9701-ea0c08d317fd"
   },
   "outputs": [],
   "source": [
    "DATASET_PATH0"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "d09e2f08-30a7-4171-94a7-c7eb66d65a3f",
   "metadata": {
    "id": "d09e2f08-30a7-4171-94a7-c7eb66d65a3f"
   },
   "outputs": [],
   "source": [
    "#export\n",
    "if __name__ == '__main__':\n",
    "    pass"
   ]
  }
 ],
 "metadata": {
  "accelerator": "TPU",
  "colab": {
   "collapsed_sections": [],
   "machine_shape": "hm",
   "name": "master.ipynb",
   "provenance": []
  },
  "gpuClass": "standard",
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.8.10"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
