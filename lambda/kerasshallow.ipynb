{
  "nbformat": 4,
  "nbformat_minor": 0,
  "metadata": {
    "colab": {
      "name": "kerasshallow.ipynb",
      "provenance": [],
      "collapsed_sections": [],
      "machine_shape": "hm"
    },
    "kernelspec": {
      "name": "python3",
      "display_name": "Python 3"
    },
    "language_info": {
      "name": "python"
    },
    "accelerator": "TPU"
  },
  "cells": [
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "RAnCMHfqJ_Pe",
        "outputId": "a7e9f6ab-9193-4d25-ad83-6fb849eadd86"
      },
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Drive already mounted at /content/drive; to attempt to forcibly remount, call drive.mount(\"/content/drive\", force_remount=True).\n"
          ]
        }
      ],
      "source": [
        "from google.colab import drive\n",
        "drive.mount('/content/drive')\n",
        "\n",
        "pathG='/content/drive/MyDrive/Pract/data' # @Reece, change this to your PathG\n",
        "# @Reece, put greyimg.zip in your pathG\n",
        "\n",
        "#pathG='../data'\n",
        "\n",
        "\n",
        "\n",
        "#cp = '/content/drive/MyDrive/Pretrained/wav2vec_small.pt'\n",
        "#sample=\"/content/drive/MyDrive/Pract/data/voice_samples/1173_GM1001_1326493712.wav\""
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "#!/usr/bin/env python3\n",
        "# -*- coding: utf-8 -*-\n",
        "\"\"\"\n",
        "Created on Tue Jun  7 20:48:17 2022\n",
        "\n",
        "@author: sanjeev\n",
        "\"\"\"\n",
        "\n",
        "import argparse\n",
        "import math\n",
        "import sys\n",
        "import time\n",
        "import copy\n",
        "import numpy as np\n",
        "\n",
        "import keras\n",
        "from keras import regularizers\n",
        "from keras.models import Sequential, Model\n",
        "from keras.layers import Dense, Dropout, Flatten, Activation, BatchNormalization #, regularizers\n",
        "from keras.layers.noise import GaussianNoise\n",
        "from keras.layers import Conv2D, MaxPooling2D,AveragePooling2D\n",
        "from keras import backend as K\n",
        "from keras.callbacks import ModelCheckpoint, EarlyStopping\n",
        "from keras.utils.np_utils import to_categorical\n",
        "\n",
        "\n",
        "import os\n",
        "\n",
        "#os.chdir('/media/sanjeev/Data/Pract/Practicum/codesNdata/mycode')\n",
        "#pathG='../data'\n",
        "\n",
        "import pandas as pd\n",
        "df=pd.read_csv(pathG+\"/labels/Yared Alemu_fear.csv\")\n",
        "df = df.reset_index()\n",
        "df['name2'] =df['name'].apply (lambda x: x.split(\".\")[0]+\".png\")\n",
        "\n",
        "\n",
        "import glob\n",
        "from PIL import Image\n",
        "import os\n",
        "imgPath= pathG+\"/greyimg\" \n",
        "\n",
        "import cv2\n",
        "imgPath = \"/content/drive/MyDrive/Pract/data/images\"\n",
        "\n",
        "resize=224\n",
        "\n",
        "\n",
        "filenames= glob.glob(imgPath+\"/*.png\" )\n",
        "filenames = [os.path.basename(x) for x in filenames]\n",
        "\n",
        "fl= imgPath+\"/\"+df.iloc[0]['name2']\n",
        "img = cv2.imread(fl)\n",
        "res = cv2.resize(img, dsize=(resize, resize), interpolation=cv2.INTER_CUBIC)\n",
        "x = (res/resize).reshape(1,resize,resize,3)\n",
        "arr = x #np.expand_dims(x, axis=0) \n",
        "#print(arr.shape)\n",
        "for i,row in df.iterrows():\n",
        "    if i>0:\n",
        "        fl = imgPath+\"/\"+row['name2']\n",
        "        img = cv2.imread(fl)\n",
        "        res = cv2.resize(img, dsize=(resize, resize), interpolation=cv2.INTER_CUBIC)\n",
        "        x = (res/resize) .reshape(1,resize,resize,3)  \n",
        "        \n",
        "        arr2 = x #np.expand_dims(ft, axis=0)\n",
        "        #print(arr2.shape)\n",
        "        arr = np.vstack((arr,arr2))\n",
        "labels=np.array(df.emotion)\n"
      ],
      "metadata": {
        "id": "mGyDnMHUKF7r"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "arr.shape"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "4vrZobITlbFu",
        "outputId": "29f98ac0-dd43-4640-adcd-eb4ec13f6b60"
      },
      "execution_count": null,
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "(530, 224, 224, 3)"
            ]
          },
          "metadata": {},
          "execution_count": 3
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "\n",
        "from sklearn.model_selection import train_test_split\n",
        "train_x, val_x, train_y, val_y = train_test_split(arr, labels, test_size = 0.3)\n",
        "\n",
        "\n",
        "# converting training images into torch format\n",
        "#train_x = train_x.reshape(train_x.shape[0], train_x.shape[1], train_x.shape[2],1)\n",
        "\n",
        "\n",
        "# converting the target into torch format\n",
        "train_y = train_y.astype(int)\n",
        "\n",
        "\n",
        "# shape of training data\n",
        "train_x.shape, train_y.shape\n",
        "# converting validation images into torch format\n",
        "#val_x = val_x.reshape(val_x.shape[0],  val_x.shape[1], val_x.shape[2],1)\n",
        "\n",
        "\n",
        "# converting the target into torch format\n",
        "val_y = val_y.astype(int)\n",
        "\n",
        "\n"
      ],
      "metadata": {
        "id": "4Rlkc5kSlJ0w"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "\n",
        "\n",
        "#K.set_image_dim_ordering('th')\n",
        "#print(K.image_data_format())\n",
        "\n",
        "## required for efficient GPU use\n",
        "import tensorflow.compat.v1 as tf\n",
        "tf.disable_v2_behavior()\n",
        "\n",
        "#from tensorflow.keras.backend import tensorflow_backend\n",
        "from tensorflow.compat.v1.keras.backend import set_session\n",
        "config = tf.ConfigProto(gpu_options=tf.GPUOptions(allow_growth=True))\n",
        "session = tf.Session(config=config)\n",
        "set_session(session)\n",
        "## required for efficient GPU use\n",
        "## required for efficient GPU use\n",
        "\n",
        "import os\n",
        "\n",
        "import pandas as pd # data processing, CSV file I/O (e.g. pd.read_csv)\n",
        "import numpy as np # linear algebra\n",
        "\n",
        "# define path to save model\n",
        "model_path = './fm_cnn_BN.h5'\n",
        "# prepare callbacks\n",
        "callbacks = [\n",
        "    EarlyStopping(\n",
        "        monitor='val_acc', \n",
        "        patience=10,\n",
        "        mode='max',\n",
        "        verbose=1),\n",
        "    ModelCheckpoint(model_path,\n",
        "        monitor='val_acc', \n",
        "        save_best_only=True, \n",
        "        mode='max',\n",
        "        verbose=0)\n",
        "]\n",
        "\n",
        "\n",
        "# get data\n",
        "\n",
        "\n",
        "#reshape data\n",
        "y_train_CNN = train_y\n",
        "X_train_CNN = train_x\n",
        "print('train shape after reshape: {}'.format(X_train_CNN.shape))\n",
        "\n",
        "y_test_CNN = val_y\n",
        "X_test_CNN = val_x\n",
        "print('test shape after reshape: {}'.format(X_test_CNN.shape))\n",
        "\n",
        "# one hot encode outputs\n",
        "y_train_CNN = to_categorical(y_train_CNN)\n",
        "y_test_CNN = to_categorical(y_test_CNN)\n",
        "num_classes = y_train_CNN.shape[1]\n",
        "\n",
        "# normalize inputs from 0-255 to 0-1\n",
        "#X_train_CNN = X_train_CNN / 255\n",
        "#X_test_CNN = X_test_CNN / 255\n",
        "\n",
        "#size of parameters\n",
        "batch_size = 32\n",
        "num_classes = 2\n",
        "epochs = 50\n",
        "filter_pixel=3\n",
        "noise = 1\n",
        "droprate=0.25\n",
        "\n",
        "# input image dimensions\n",
        "img_rows, img_cols = 224, 224\n",
        "\n",
        "input_shape = ( img_rows, img_cols,3)\n",
        "\n",
        "#Start Neural Network\n",
        "model = Sequential()\n",
        "#convolution 1st layer\n",
        "model.add(Conv2D(8, kernel_size=(3, 3), \n",
        "                 activation='relu', padding=\"same\",\n",
        "                 input_shape=input_shape)) \n",
        "model.add(AveragePooling2D(pool_size=(2, 2)))\n",
        "\n",
        "\n",
        "#convolution 2nd layer\n",
        "model.add(Conv2D(16, kernel_size=(3, 3),  padding=\"same\",\n",
        "                 activation='relu')) \n",
        "model.add(AveragePooling2D(pool_size=(2, 2)))\n",
        "\n",
        "#convolution 3rd layer\n",
        "model.add(Conv2D(32, kernel_size=(3, 3),  padding=\"same\",\n",
        "                 activation='relu')) \n",
        "model.add(AveragePooling2D(pool_size=(2, 2)))\n",
        "\n",
        "\n",
        "#Fully connected 1st layer\n",
        "model.add(Flatten())\n",
        "model.add(Dense(25088,use_bias=True)) \n",
        "model.add(Activation('relu')) \n",
        "#model.add(Dropout(droprate)) \n",
        "\n",
        "model.add(Dense(2048,use_bias=True)) \n",
        "model.add(Activation('relu'))   \n",
        "\n",
        "\n",
        "model.add(Dense(2048, use_bias=True)) \n",
        "model.add(Activation('relu'))      \n",
        "\n",
        "#Fully connected final layer\n",
        "model.add(Dense(2)) \n",
        "model.add(Activation('softmax')) \n",
        "\n"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "JEC5DSDNlV3e",
        "outputId": "17ffc68e-f2d8-4449-bdbe-8c3e0c57aee4"
      },
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "train shape after reshape: (371, 224, 224, 3)\n",
            "test shape after reshape: (159, 224, 224, 3)\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "\n",
        "model.compile(loss=keras.losses.categorical_crossentropy,\n",
        "              optimizer=keras.optimizers.rmsprop_v2.RMSProp(),\n",
        "              metrics=[2*tf.keras.metrics.Recall() * tf.keras.metrics.Precision()/(tf.keras.metrics.Recall()+tf.keras.metrics.Precision())])\n",
        "\n",
        "model.summary()\n",
        "\n",
        "#Save Model=ON\n",
        "history = model.fit(X_train_CNN, y_train_CNN,\n",
        "          batch_size=batch_size,\n",
        "          epochs=epochs,\n",
        "          verbose=1,\n",
        "          validation_data=(X_test_CNN, y_test_CNN),shuffle=True,callbacks=callbacks)\n",
        "\n",
        "score = model.evaluate(X_test_CNN, y_test_CNN, verbose=1)\n",
        "\n",
        "#print loss and accuracy\n",
        "print('Test loss:', score[0])\n",
        "print('Test accuracy:', score[1])"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 254
        },
        "id": "myydnnyCLNMS",
        "outputId": "25466110-9d15-42a8-e43d-6d5c4ec23894"
      },
      "execution_count": null,
      "outputs": [
        {
          "output_type": "error",
          "ename": "TypeError",
          "evalue": "ignored",
          "traceback": [
            "\u001b[0;31m---------------------------------------------------------------------------\u001b[0m",
            "\u001b[0;31mTypeError\u001b[0m                                 Traceback (most recent call last)",
            "\u001b[0;32m<ipython-input-9-b09866aad738>\u001b[0m in \u001b[0;36m<module>\u001b[0;34m()\u001b[0m\n\u001b[1;32m      2\u001b[0m model.compile(loss=keras.losses.categorical_crossentropy,\n\u001b[1;32m      3\u001b[0m               \u001b[0moptimizer\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0mkeras\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0moptimizers\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mrmsprop_v2\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mRMSProp\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m,\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m----> 4\u001b[0;31m               metrics=[2*tf.keras.metrics.Recall() * tf.keras.metrics.Precision()/(tf.keras.metrics.Recall()+tf.keras.metrics.Precision())])\n\u001b[0m\u001b[1;32m      5\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m      6\u001b[0m \u001b[0mmodel\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0msummary\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
            "\u001b[0;31mTypeError\u001b[0m: unsupported operand type(s) for *: 'int' and 'Recall'"
          ]
        }
      ]
    }
  ]
}