{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "id": "07191bff-49a7-4534-b355-6e4f90b9737d",
   "metadata": {
    "id": "f5351569-b942-48eb-aa96-3491bd07b6f2"
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Requirement already satisfied: pandas==1.4.0 in /home/ubuntu/.local/lib/python3.8/site-packages (1.4.0)\n",
      "Requirement already satisfied: numpy==1.20.0 in /home/ubuntu/.local/lib/python3.8/site-packages (1.20.0)\n",
      "Requirement already satisfied: python-dateutil>=2.8.1 in /home/ubuntu/.local/lib/python3.8/site-packages (from pandas==1.4.0) (2.8.2)\n",
      "Requirement already satisfied: pytz>=2020.1 in /home/ubuntu/.local/lib/python3.8/site-packages (from pandas==1.4.0) (2022.1)\n",
      "Requirement already satisfied: six>=1.5 in /usr/lib/python3/dist-packages (from python-dateutil>=2.8.1->pandas==1.4.0) (1.14.0)\n",
      "Requirement already satisfied: keras_self_attention in /home/ubuntu/.local/lib/python3.8/site-packages (0.51.0)\n",
      "Requirement already satisfied: nbdev in /home/ubuntu/.local/lib/python3.8/site-packages (1.2.10)\n",
      "Requirement already satisfied: torchaudio==0.10.1 in /home/ubuntu/.local/lib/python3.8/site-packages (0.10.1)\n",
      "Requirement already satisfied: attention in /home/ubuntu/.local/lib/python3.8/site-packages (4.1)\n",
      "Requirement already satisfied: pyyaml in /usr/lib/python3/dist-packages (5.3.1)\n",
      "Requirement already satisfied: h5py in /usr/lib/python3/dist-packages (2.10.0)\n",
      "Requirement already satisfied: nvidia_smi in /home/ubuntu/.local/lib/python3.8/site-packages (0.1.3)\n",
      "Requirement already satisfied: keras==2.9.0rc1 in /home/ubuntu/.local/lib/python3.8/site-packages (2.9.0rc1)\n",
      "Requirement already satisfied: numpy in /home/ubuntu/.local/lib/python3.8/site-packages (from keras_self_attention) (1.20.0)\n",
      "Requirement already satisfied: Jinja2 in /home/ubuntu/.local/lib/python3.8/site-packages (from nbdev) (3.1.2)\n",
      "Requirement already satisfied: pip in /usr/lib/python3/dist-packages (from nbdev) (20.0.2)\n",
      "Requirement already satisfied: nbformat>=4.4.0 in /home/ubuntu/.local/lib/python3.8/site-packages (from nbdev) (5.4.0)\n",
      "Requirement already satisfied: jupyter-client<8 in /home/ubuntu/.local/lib/python3.8/site-packages (from nbdev) (7.3.1)\n",
      "Requirement already satisfied: ipykernel in /usr/lib/python3/dist-packages (from nbdev) (5.2.0)\n",
      "Requirement already satisfied: nbconvert>=6.1 in /home/ubuntu/.local/lib/python3.8/site-packages (from nbdev) (6.5.0)\n",
      "Requirement already satisfied: ghapi in /home/ubuntu/.local/lib/python3.8/site-packages (from nbdev) (0.1.21)\n",
      "Requirement already satisfied: fastcore>=1.4.1 in /home/ubuntu/.local/lib/python3.8/site-packages (from nbdev) (1.4.5)\n",
      "Requirement already satisfied: packaging in /usr/lib/python3/dist-packages (from nbdev) (20.3)\n",
      "Requirement already satisfied: jupyter in /home/ubuntu/.local/lib/python3.8/site-packages (from nbdev) (1.0.0)\n",
      "Requirement already satisfied: fastrelease in /home/ubuntu/.local/lib/python3.8/site-packages (from nbdev) (0.1.16)\n",
      "Requirement already satisfied: torch==1.10.1 in /home/ubuntu/.local/lib/python3.8/site-packages (from torchaudio==0.10.1) (1.10.1)\n",
      "Requirement already satisfied: tensorflow>=2.1 in /home/ubuntu/.local/lib/python3.8/site-packages (from attention) (2.9.1)\n",
      "Requirement already satisfied: sorcery>=0.1.0 in /home/ubuntu/.local/lib/python3.8/site-packages (from nvidia_smi) (0.2.2)\n",
      "Requirement already satisfied: pytest>=4.3.1 in /home/ubuntu/.local/lib/python3.8/site-packages (from nvidia_smi) (7.1.2)\n",
      "Requirement already satisfied: six>=1.12.0 in /usr/lib/python3/dist-packages (from nvidia_smi) (1.14.0)\n",
      "Requirement already satisfied: MarkupSafe>=2.0 in /home/ubuntu/.local/lib/python3.8/site-packages (from Jinja2->nbdev) (2.1.1)\n",
      "Requirement already satisfied: fastjsonschema in /home/ubuntu/.local/lib/python3.8/site-packages (from nbformat>=4.4.0->nbdev) (2.15.3)\n",
      "Requirement already satisfied: jupyter-core in /home/ubuntu/.local/lib/python3.8/site-packages (from nbformat>=4.4.0->nbdev) (4.10.0)\n",
      "Requirement already satisfied: jsonschema>=2.6 in /usr/lib/python3/dist-packages (from nbformat>=4.4.0->nbdev) (3.2.0)\n",
      "Requirement already satisfied: traitlets>=5.1 in /home/ubuntu/.local/lib/python3.8/site-packages (from nbformat>=4.4.0->nbdev) (5.2.1.post0)\n",
      "Requirement already satisfied: pyzmq>=22.3 in /home/ubuntu/.local/lib/python3.8/site-packages (from jupyter-client<8->nbdev) (23.0.0)\n",
      "Requirement already satisfied: python-dateutil>=2.8.2 in /home/ubuntu/.local/lib/python3.8/site-packages (from jupyter-client<8->nbdev) (2.8.2)\n",
      "Requirement already satisfied: entrypoints in /usr/lib/python3/dist-packages (from jupyter-client<8->nbdev) (0.3)\n",
      "Requirement already satisfied: nest-asyncio>=1.5.4 in /home/ubuntu/.local/lib/python3.8/site-packages (from jupyter-client<8->nbdev) (1.5.5)\n",
      "Requirement already satisfied: tornado>=6.0 in /home/ubuntu/.local/lib/python3.8/site-packages (from jupyter-client<8->nbdev) (6.1)\n",
      "Requirement already satisfied: pygments>=2.4.1 in /home/ubuntu/.local/lib/python3.8/site-packages (from nbconvert>=6.1->nbdev) (2.12.0)\n",
      "Requirement already satisfied: pandocfilters>=1.4.1 in /home/ubuntu/.local/lib/python3.8/site-packages (from nbconvert>=6.1->nbdev) (1.5.0)\n",
      "Requirement already satisfied: beautifulsoup4 in /home/ubuntu/.local/lib/python3.8/site-packages (from nbconvert>=6.1->nbdev) (4.11.1)\n",
      "Requirement already satisfied: mistune<2,>=0.8.1 in /home/ubuntu/.local/lib/python3.8/site-packages (from nbconvert>=6.1->nbdev) (0.8.4)\n",
      "Requirement already satisfied: nbclient>=0.5.0 in /home/ubuntu/.local/lib/python3.8/site-packages (from nbconvert>=6.1->nbdev) (0.6.3)\n",
      "Requirement already satisfied: tinycss2 in /home/ubuntu/.local/lib/python3.8/site-packages (from nbconvert>=6.1->nbdev) (1.1.1)\n",
      "Requirement already satisfied: defusedxml in /home/ubuntu/.local/lib/python3.8/site-packages (from nbconvert>=6.1->nbdev) (0.7.1)\n",
      "Requirement already satisfied: jupyterlab-pygments in /home/ubuntu/.local/lib/python3.8/site-packages (from nbconvert>=6.1->nbdev) (0.2.2)\n",
      "Requirement already satisfied: bleach in /usr/lib/python3/dist-packages (from nbconvert>=6.1->nbdev) (3.1.1)\n",
      "Requirement already satisfied: notebook in /home/ubuntu/.local/lib/python3.8/site-packages (from jupyter->nbdev) (6.4.11)\n",
      "Requirement already satisfied: qtconsole in /home/ubuntu/.local/lib/python3.8/site-packages (from jupyter->nbdev) (5.3.1)\n",
      "Requirement already satisfied: ipywidgets in /home/ubuntu/.local/lib/python3.8/site-packages (from jupyter->nbdev) (7.7.0)\n",
      "Requirement already satisfied: jupyter-console in /usr/lib/python3/dist-packages (from jupyter->nbdev) (6.0.0)\n",
      "Requirement already satisfied: typing-extensions in /home/ubuntu/.local/lib/python3.8/site-packages (from torch==1.10.1->torchaudio==0.10.1) (4.2.0)\n",
      "Requirement already satisfied: libclang>=13.0.0 in /home/ubuntu/.local/lib/python3.8/site-packages (from tensorflow>=2.1->attention) (14.0.1)\n",
      "Requirement already satisfied: astunparse>=1.6.0 in /usr/lib/python3/dist-packages (from tensorflow>=2.1->attention) (1.6.2)\n",
      "Requirement already satisfied: absl-py>=1.0.0 in /home/ubuntu/.local/lib/python3.8/site-packages (from tensorflow>=2.1->attention) (1.1.0)\n",
      "Requirement already satisfied: termcolor>=1.1.0 in /usr/lib/python3/dist-packages (from tensorflow>=2.1->attention) (1.1.0)\n",
      "Requirement already satisfied: gast<=0.4.0,>=0.2.1 in /usr/lib/python3/dist-packages (from tensorflow>=2.1->attention) (0.4.0)\n",
      "Requirement already satisfied: grpcio<2.0,>=1.24.3 in /usr/lib/python3/dist-packages (from tensorflow>=2.1->attention) (1.29.1)\n",
      "Requirement already satisfied: keras-preprocessing>=1.1.1 in /usr/lib/python3/dist-packages (from tensorflow>=2.1->attention) (1.1.2)\n",
      "Requirement already satisfied: setuptools in /usr/lib/python3/dist-packages (from tensorflow>=2.1->attention) (45.2.0)\n",
      "Requirement already satisfied: tensorflow-io-gcs-filesystem>=0.23.1 in /home/ubuntu/.local/lib/python3.8/site-packages (from tensorflow>=2.1->attention) (0.26.0)\n",
      "Requirement already satisfied: flatbuffers<2,>=1.12 in /usr/lib/python3/dist-packages (from tensorflow>=2.1->attention) (1.12)\n",
      "Requirement already satisfied: tensorboard<2.10,>=2.9 in /home/ubuntu/.local/lib/python3.8/site-packages (from tensorflow>=2.1->attention) (2.9.1)\n",
      "Requirement already satisfied: protobuf<3.20,>=3.9.2 in /usr/lib/python3/dist-packages (from tensorflow>=2.1->attention) (3.11.4)\n",
      "Requirement already satisfied: wrapt>=1.11.0 in /usr/lib/python3/dist-packages (from tensorflow>=2.1->attention) (1.11.2)\n",
      "Requirement already satisfied: tensorflow-estimator<2.10.0,>=2.9.0rc0 in /home/ubuntu/.local/lib/python3.8/site-packages (from tensorflow>=2.1->attention) (2.9.0)\n",
      "Requirement already satisfied: google-pasta>=0.1.1 in /usr/lib/python3/dist-packages (from tensorflow>=2.1->attention) (0.2.0)\n",
      "Requirement already satisfied: opt-einsum>=2.3.2 in /usr/lib/python3/dist-packages (from tensorflow>=2.1->attention) (3.3.0)\n",
      "Requirement already satisfied: littleutils>=0.2.1 in /home/ubuntu/.local/lib/python3.8/site-packages (from sorcery>=0.1.0->nvidia_smi) (0.2.2)\n",
      "Requirement already satisfied: executing in /home/ubuntu/.local/lib/python3.8/site-packages (from sorcery>=0.1.0->nvidia_smi) (0.8.3)\n",
      "Requirement already satisfied: asttokens in /home/ubuntu/.local/lib/python3.8/site-packages (from sorcery>=0.1.0->nvidia_smi) (2.0.5)\n",
      "Requirement already satisfied: tomli>=1.0.0 in /home/ubuntu/.local/lib/python3.8/site-packages (from pytest>=4.3.1->nvidia_smi) (2.0.1)\n",
      "Requirement already satisfied: attrs>=19.2.0 in /usr/lib/python3/dist-packages (from pytest>=4.3.1->nvidia_smi) (19.3.0)\n",
      "Requirement already satisfied: pluggy<2.0,>=0.12 in /home/ubuntu/.local/lib/python3.8/site-packages (from pytest>=4.3.1->nvidia_smi) (1.0.0)\n",
      "Requirement already satisfied: iniconfig in /home/ubuntu/.local/lib/python3.8/site-packages (from pytest>=4.3.1->nvidia_smi) (1.1.1)\n",
      "Requirement already satisfied: py>=1.8.2 in /home/ubuntu/.local/lib/python3.8/site-packages (from pytest>=4.3.1->nvidia_smi) (1.11.0)\n",
      "Requirement already satisfied: soupsieve>1.2 in /home/ubuntu/.local/lib/python3.8/site-packages (from beautifulsoup4->nbconvert>=6.1->nbdev) (2.3.2.post1)\n",
      "Requirement already satisfied: webencodings>=0.4 in /usr/lib/python3/dist-packages (from tinycss2->nbconvert>=6.1->nbdev) (0.5.1)\n",
      "Requirement already satisfied: terminado>=0.8.3 in /home/ubuntu/.local/lib/python3.8/site-packages (from notebook->jupyter->nbdev) (0.15.0)\n",
      "Requirement already satisfied: prometheus-client in /home/ubuntu/.local/lib/python3.8/site-packages (from notebook->jupyter->nbdev) (0.14.1)\n",
      "Requirement already satisfied: ipython-genutils in /usr/lib/python3/dist-packages (from notebook->jupyter->nbdev) (0.2.0)\n",
      "Requirement already satisfied: Send2Trash>=1.8.0 in /home/ubuntu/.local/lib/python3.8/site-packages (from notebook->jupyter->nbdev) (1.8.0)\n",
      "Requirement already satisfied: argon2-cffi in /home/ubuntu/.local/lib/python3.8/site-packages (from notebook->jupyter->nbdev) (21.3.0)\n",
      "Requirement already satisfied: qtpy>=2.0.1 in /home/ubuntu/.local/lib/python3.8/site-packages (from qtconsole->jupyter->nbdev) (2.1.0)\n",
      "Requirement already satisfied: widgetsnbextension~=3.6.0 in /home/ubuntu/.local/lib/python3.8/site-packages (from ipywidgets->jupyter->nbdev) (3.6.0)\n",
      "Requirement already satisfied: jupyterlab-widgets>=1.0.0; python_version >= \"3.6\" in /home/ubuntu/.local/lib/python3.8/site-packages (from ipywidgets->jupyter->nbdev) (1.1.0)\n",
      "Requirement already satisfied: ipython>=4.0.0; python_version >= \"3.3\" in /usr/lib/python3/dist-packages (from ipywidgets->jupyter->nbdev) (7.13.0)\n",
      "Requirement already satisfied: wheel>=0.26 in /usr/lib/python3/dist-packages (from tensorboard<2.10,>=2.9->tensorflow>=2.1->attention) (0.34.2)\n",
      "Requirement already satisfied: google-auth-oauthlib<0.5,>=0.4.1 in /usr/lib/python3/dist-packages (from tensorboard<2.10,>=2.9->tensorflow>=2.1->attention) (0.4.1)\n",
      "Requirement already satisfied: tensorboard-plugin-wit>=1.6.0 in /home/ubuntu/.local/lib/python3.8/site-packages (from tensorboard<2.10,>=2.9->tensorflow>=2.1->attention) (1.8.1)\n",
      "Requirement already satisfied: werkzeug>=1.0.1 in /home/ubuntu/.local/lib/python3.8/site-packages (from tensorboard<2.10,>=2.9->tensorflow>=2.1->attention) (2.1.2)\n",
      "Requirement already satisfied: markdown>=2.6.8 in /usr/lib/python3/dist-packages (from tensorboard<2.10,>=2.9->tensorflow>=2.1->attention) (3.1.1)\n",
      "Requirement already satisfied: requests<3,>=2.21.0 in /home/ubuntu/.local/lib/python3.8/site-packages (from tensorboard<2.10,>=2.9->tensorflow>=2.1->attention) (2.27.1)\n",
      "Requirement already satisfied: google-auth<3,>=1.6.3 in /home/ubuntu/.local/lib/python3.8/site-packages (from tensorboard<2.10,>=2.9->tensorflow>=2.1->attention) (2.9.0)\n",
      "Requirement already satisfied: tensorboard-data-server<0.7.0,>=0.6.0 in /home/ubuntu/.local/lib/python3.8/site-packages (from tensorboard<2.10,>=2.9->tensorflow>=2.1->attention) (0.6.1)\n",
      "Requirement already satisfied: ptyprocess; os_name != \"nt\" in /home/ubuntu/.local/lib/python3.8/site-packages (from terminado>=0.8.3->notebook->jupyter->nbdev) (0.7.0)\n",
      "Requirement already satisfied: argon2-cffi-bindings in /home/ubuntu/.local/lib/python3.8/site-packages (from argon2-cffi->notebook->jupyter->nbdev) (21.2.0)\n",
      "Requirement already satisfied: pexpect in /usr/lib/python3/dist-packages (from ipython>=4.0.0; python_version >= \"3.3\"->ipywidgets->jupyter->nbdev) (4.6.0)\n",
      "Requirement already satisfied: urllib3<1.27,>=1.21.1 in /usr/lib/python3/dist-packages (from requests<3,>=2.21.0->tensorboard<2.10,>=2.9->tensorflow>=2.1->attention) (1.25.8)\n",
      "Requirement already satisfied: certifi>=2017.4.17 in /usr/lib/python3/dist-packages (from requests<3,>=2.21.0->tensorboard<2.10,>=2.9->tensorflow>=2.1->attention) (2019.11.28)\n",
      "Requirement already satisfied: charset-normalizer~=2.0.0; python_version >= \"3\" in /home/ubuntu/.local/lib/python3.8/site-packages (from requests<3,>=2.21.0->tensorboard<2.10,>=2.9->tensorflow>=2.1->attention) (2.0.12)\n",
      "Requirement already satisfied: idna<4,>=2.5; python_version >= \"3\" in /usr/lib/python3/dist-packages (from requests<3,>=2.21.0->tensorboard<2.10,>=2.9->tensorflow>=2.1->attention) (2.8)\n",
      "Requirement already satisfied: pyasn1-modules>=0.2.1 in /usr/lib/python3/dist-packages (from google-auth<3,>=1.6.3->tensorboard<2.10,>=2.9->tensorflow>=2.1->attention) (0.2.1)\n",
      "Requirement already satisfied: cachetools<6.0,>=2.0.0 in /usr/lib/python3/dist-packages (from google-auth<3,>=1.6.3->tensorboard<2.10,>=2.9->tensorflow>=2.1->attention) (4.0.0)\n",
      "Requirement already satisfied: rsa<5,>=3.1.4; python_version >= \"3.6\" in /usr/lib/python3/dist-packages (from google-auth<3,>=1.6.3->tensorboard<2.10,>=2.9->tensorflow>=2.1->attention) (4.0)\n",
      "Requirement already satisfied: cffi>=1.0.1 in /home/ubuntu/.local/lib/python3.8/site-packages (from argon2-cffi-bindings->argon2-cffi->notebook->jupyter->nbdev) (1.15.0)\n",
      "Requirement already satisfied: pycparser in /home/ubuntu/.local/lib/python3.8/site-packages (from cffi>=1.0.1->argon2-cffi-bindings->argon2-cffi->notebook->jupyter->nbdev) (2.21)\n",
      "Requirement already satisfied: tensorflow in /home/ubuntu/.local/lib/python3.8/site-packages (2.9.1)\n",
      "Requirement already satisfied: librosa in /home/ubuntu/.local/lib/python3.8/site-packages (0.9.2)\n",
      "Requirement already satisfied: matplotlib in /home/ubuntu/.local/lib/python3.8/site-packages (3.5.2)\n",
      "Requirement already satisfied: pickle5 in /home/ubuntu/.local/lib/python3.8/site-packages (0.0.11)\n",
      "Requirement already satisfied: Pillow in /usr/lib/python3/dist-packages (7.0.0)\n",
      "Requirement already satisfied: opencv-python in /home/ubuntu/.local/lib/python3.8/site-packages (4.6.0.66)\n",
      "Requirement already satisfied: numba in /home/ubuntu/.local/lib/python3.8/site-packages (0.55.2)\n",
      "Requirement already satisfied: tensorboard<2.10,>=2.9 in /home/ubuntu/.local/lib/python3.8/site-packages (from tensorflow) (2.9.1)\n",
      "Requirement already satisfied: astunparse>=1.6.0 in /usr/lib/python3/dist-packages (from tensorflow) (1.6.2)\n",
      "Requirement already satisfied: tensorflow-io-gcs-filesystem>=0.23.1 in /home/ubuntu/.local/lib/python3.8/site-packages (from tensorflow) (0.26.0)\n",
      "Requirement already satisfied: tensorflow-estimator<2.10.0,>=2.9.0rc0 in /home/ubuntu/.local/lib/python3.8/site-packages (from tensorflow) (2.9.0)\n",
      "Requirement already satisfied: termcolor>=1.1.0 in /usr/lib/python3/dist-packages (from tensorflow) (1.1.0)\n",
      "Requirement already satisfied: numpy>=1.20 in /home/ubuntu/.local/lib/python3.8/site-packages (from tensorflow) (1.20.0)\n",
      "Requirement already satisfied: packaging in /usr/lib/python3/dist-packages (from tensorflow) (20.3)\n",
      "Requirement already satisfied: typing-extensions>=3.6.6 in /home/ubuntu/.local/lib/python3.8/site-packages (from tensorflow) (4.2.0)\n",
      "Requirement already satisfied: flatbuffers<2,>=1.12 in /usr/lib/python3/dist-packages (from tensorflow) (1.12)\n",
      "Requirement already satisfied: keras-preprocessing>=1.1.1 in /usr/lib/python3/dist-packages (from tensorflow) (1.1.2)\n",
      "Requirement already satisfied: google-pasta>=0.1.1 in /usr/lib/python3/dist-packages (from tensorflow) (0.2.0)\n",
      "Requirement already satisfied: h5py>=2.9.0 in /usr/lib/python3/dist-packages (from tensorflow) (2.10.0)\n",
      "Requirement already satisfied: libclang>=13.0.0 in /home/ubuntu/.local/lib/python3.8/site-packages (from tensorflow) (14.0.1)\n",
      "Requirement already satisfied: grpcio<2.0,>=1.24.3 in /usr/lib/python3/dist-packages (from tensorflow) (1.29.1)\n",
      "Requirement already satisfied: setuptools in /usr/lib/python3/dist-packages (from tensorflow) (45.2.0)\n",
      "Requirement already satisfied: wrapt>=1.11.0 in /usr/lib/python3/dist-packages (from tensorflow) (1.11.2)\n",
      "Requirement already satisfied: keras<2.10.0,>=2.9.0rc0 in /home/ubuntu/.local/lib/python3.8/site-packages (from tensorflow) (2.9.0rc1)\n",
      "Requirement already satisfied: absl-py>=1.0.0 in /home/ubuntu/.local/lib/python3.8/site-packages (from tensorflow) (1.1.0)\n",
      "Requirement already satisfied: gast<=0.4.0,>=0.2.1 in /usr/lib/python3/dist-packages (from tensorflow) (0.4.0)\n",
      "Requirement already satisfied: six>=1.12.0 in /usr/lib/python3/dist-packages (from tensorflow) (1.14.0)\n",
      "Requirement already satisfied: opt-einsum>=2.3.2 in /usr/lib/python3/dist-packages (from tensorflow) (3.3.0)\n",
      "Requirement already satisfied: protobuf<3.20,>=3.9.2 in /usr/lib/python3/dist-packages (from tensorflow) (3.11.4)\n",
      "Requirement already satisfied: scipy>=1.2.0 in /home/ubuntu/.local/lib/python3.8/site-packages (from librosa) (1.8.1)\n",
      "Requirement already satisfied: scikit-learn>=0.19.1 in /usr/lib/python3/dist-packages (from librosa) (0.22.2.post1)\n",
      "Requirement already satisfied: decorator>=4.0.10 in /usr/lib/python3/dist-packages (from librosa) (4.4.2)\n",
      "Requirement already satisfied: joblib>=0.14 in /home/ubuntu/.local/lib/python3.8/site-packages (from librosa) (1.1.0)\n",
      "Requirement already satisfied: soundfile>=0.10.2 in /home/ubuntu/.local/lib/python3.8/site-packages (from librosa) (0.10.3.post1)\n",
      "Requirement already satisfied: resampy>=0.2.2 in /home/ubuntu/.local/lib/python3.8/site-packages (from librosa) (0.3.0)\n",
      "Requirement already satisfied: pooch>=1.0 in /home/ubuntu/.local/lib/python3.8/site-packages (from librosa) (1.6.0)\n",
      "Requirement already satisfied: audioread>=2.1.9 in /home/ubuntu/.local/lib/python3.8/site-packages (from librosa) (2.1.9)\n",
      "Requirement already satisfied: python-dateutil>=2.7 in /home/ubuntu/.local/lib/python3.8/site-packages (from matplotlib) (2.8.2)\n",
      "Requirement already satisfied: fonttools>=4.22.0 in /home/ubuntu/.local/lib/python3.8/site-packages (from matplotlib) (4.33.3)\n",
      "Requirement already satisfied: kiwisolver>=1.0.1 in /usr/lib/python3/dist-packages (from matplotlib) (1.0.1)\n",
      "Requirement already satisfied: cycler>=0.10 in /usr/lib/python3/dist-packages (from matplotlib) (0.10.0)\n",
      "Requirement already satisfied: pyparsing>=2.2.1 in /usr/lib/python3/dist-packages (from matplotlib) (2.4.6)\n",
      "Requirement already satisfied: llvmlite<0.39,>=0.38.0rc1 in /home/ubuntu/.local/lib/python3.8/site-packages (from numba) (0.38.1)\n",
      "Requirement already satisfied: requests<3,>=2.21.0 in /home/ubuntu/.local/lib/python3.8/site-packages (from tensorboard<2.10,>=2.9->tensorflow) (2.27.1)\n",
      "Requirement already satisfied: tensorboard-plugin-wit>=1.6.0 in /home/ubuntu/.local/lib/python3.8/site-packages (from tensorboard<2.10,>=2.9->tensorflow) (1.8.1)\n",
      "Requirement already satisfied: google-auth<3,>=1.6.3 in /home/ubuntu/.local/lib/python3.8/site-packages (from tensorboard<2.10,>=2.9->tensorflow) (2.9.0)\n",
      "Requirement already satisfied: markdown>=2.6.8 in /usr/lib/python3/dist-packages (from tensorboard<2.10,>=2.9->tensorflow) (3.1.1)\n",
      "Requirement already satisfied: wheel>=0.26 in /usr/lib/python3/dist-packages (from tensorboard<2.10,>=2.9->tensorflow) (0.34.2)\n",
      "Requirement already satisfied: werkzeug>=1.0.1 in /home/ubuntu/.local/lib/python3.8/site-packages (from tensorboard<2.10,>=2.9->tensorflow) (2.1.2)\n",
      "Requirement already satisfied: google-auth-oauthlib<0.5,>=0.4.1 in /usr/lib/python3/dist-packages (from tensorboard<2.10,>=2.9->tensorflow) (0.4.1)\n",
      "Requirement already satisfied: tensorboard-data-server<0.7.0,>=0.6.0 in /home/ubuntu/.local/lib/python3.8/site-packages (from tensorboard<2.10,>=2.9->tensorflow) (0.6.1)\n",
      "Requirement already satisfied: cffi>=1.0 in /home/ubuntu/.local/lib/python3.8/site-packages (from soundfile>=0.10.2->librosa) (1.15.0)\n",
      "Requirement already satisfied: appdirs>=1.3.0 in /usr/lib/python3/dist-packages (from pooch>=1.0->librosa) (1.4.3)\n",
      "Requirement already satisfied: urllib3<1.27,>=1.21.1 in /usr/lib/python3/dist-packages (from requests<3,>=2.21.0->tensorboard<2.10,>=2.9->tensorflow) (1.25.8)\n",
      "Requirement already satisfied: charset-normalizer~=2.0.0; python_version >= \"3\" in /home/ubuntu/.local/lib/python3.8/site-packages (from requests<3,>=2.21.0->tensorboard<2.10,>=2.9->tensorflow) (2.0.12)\n",
      "Requirement already satisfied: certifi>=2017.4.17 in /usr/lib/python3/dist-packages (from requests<3,>=2.21.0->tensorboard<2.10,>=2.9->tensorflow) (2019.11.28)\n",
      "Requirement already satisfied: idna<4,>=2.5; python_version >= \"3\" in /usr/lib/python3/dist-packages (from requests<3,>=2.21.0->tensorboard<2.10,>=2.9->tensorflow) (2.8)\n",
      "Requirement already satisfied: cachetools<6.0,>=2.0.0 in /usr/lib/python3/dist-packages (from google-auth<3,>=1.6.3->tensorboard<2.10,>=2.9->tensorflow) (4.0.0)\n",
      "Requirement already satisfied: rsa<5,>=3.1.4; python_version >= \"3.6\" in /usr/lib/python3/dist-packages (from google-auth<3,>=1.6.3->tensorboard<2.10,>=2.9->tensorflow) (4.0)\n",
      "Requirement already satisfied: pyasn1-modules>=0.2.1 in /usr/lib/python3/dist-packages (from google-auth<3,>=1.6.3->tensorboard<2.10,>=2.9->tensorflow) (0.2.1)\n",
      "Requirement already satisfied: pycparser in /home/ubuntu/.local/lib/python3.8/site-packages (from cffi>=1.0->soundfile>=0.10.2->librosa) (2.21)\n"
     ]
    }
   ],
   "source": [
    "!pip install  pandas==1.4.0 numpy==1.20.0\n",
    "!pip install keras_self_attention nbdev torchaudio==0.10.1 attention pyyaml h5py nvidia_smi keras==2.9.0rc1 \n",
    "!pip install tensorflow librosa matplotlib pickle5 Pillow opencv-python numba "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "id": "32f2919a-7a0a-4137-8aeb-c03882e30667",
   "metadata": {
    "id": "32f2919a-7a0a-4137-8aeb-c03882e30667"
   },
   "outputs": [],
   "source": [
    "#default_exp master"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "0eb26169-19c8-429e-a5ae-253c0f6f141a",
   "metadata": {
    "id": "ac7f51d4-0922-4ff9-9527-f418593b698a"
   },
   "outputs": [],
   "source": [
    "#export\n",
    "# Import the library\n",
    "import argparse\n",
    "# Create the parser\n",
    "parser = argparse.ArgumentParser()\n",
    "# Add an argument\n",
    "parser.add_argument('--therapist', type=str, required=True)\n",
    "parser.add_argument('--emotion', type=str, required=True)\n",
    "parser.add_argument('--name', type=str, required=True)\n",
    "parser.add_argument('--IsImage', type=str, required=False, default=1)\n",
    "parser.add_argument('--featureType', type=str, required=False, default='')\n",
    "parser.add_argument('--use_existing_model', type=str, required=False, default='no')\n",
    "parser.add_argument('--duration', type=str, required=False, default=60)\n",
    "# Parse the argument\n",
    "args = parser.parse_args()\n",
    "\n",
    "therapist= args.therapist\n",
    "emotion=args.emotion\n",
    "name=args.name\n",
    "use_existing_model= args.use_existing_model\n",
    "img=args.IsImage\n",
    "feat=args.featureType\n",
    "t=args.duration"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "AVq7hvFNaDKX",
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/"
    },
    "executionInfo": {
     "elapsed": 915,
     "status": "ok",
     "timestamp": 1657129857496,
     "user": {
      "displayName": "Sanjeev Singh Kenwar",
      "userId": "00714071671360104547"
     },
     "user_tz": 240
    },
    "id": "AVq7hvFNaDKX",
    "outputId": "793f7e4a-0b02-493a-95c0-87cbb34d27e4"
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Drive already mounted at /content/drive; to attempt to forcibly remount, call drive.mount(\"/content/drive\", force_remount=True).\n"
     ]
    }
   ],
   "source": [
    "from google.colab import drive\n",
    "drive.mount('/content/drive')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "Q7raQR8lZyGN",
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/"
    },
    "executionInfo": {
     "elapsed": 2892,
     "status": "ok",
     "timestamp": 1657129860373,
     "user": {
      "displayName": "Sanjeev Singh Kenwar",
      "userId": "00714071671360104547"
     },
     "user_tz": 240
    },
    "id": "Q7raQR8lZyGN",
    "outputId": "440d6d78-fc13-4e9f-d64b-2963f1be5670"
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Looking in indexes: https://pypi.org/simple, https://us-python.pkg.dev/colab-wheels/public/simple/\n",
      "Requirement already satisfied: pickle5 in /usr/local/lib/python3.7/dist-packages (0.0.12)\n",
      "Requirement already satisfied: keras_self_attention in /usr/local/lib/python3.7/dist-packages (0.51.0)\n",
      "Requirement already satisfied: numpy in /usr/local/lib/python3.7/dist-packages (from keras_self_attention) (1.21.6)\n"
     ]
    }
   ],
   "source": [
    "!pip install pickle5 keras_self_attention"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "BJnBcp9-aARt",
   "metadata": {
    "id": "BJnBcp9-aARt"
   },
   "outputs": [],
   "source": [
    "import sys\n",
    "  \n",
    "# adding Folder_2 to the system path\n",
    "sys.path.insert(0, '/content/drive/MyDrive/Pract/lambda')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "id": "853ab06e-100e-471d-9f11-39e236a3c7c5",
   "metadata": {
    "id": "853ab06e-100e-471d-9f11-39e236a3c7c5"
   },
   "outputs": [],
   "source": [
    "#export\n",
    "from tensorflow.tools.docs import doc_controls\n",
    "import librosa, librosa.display\n",
    "import matplotlib.pyplot as plt\n",
    "\n",
    "import os\n",
    "import glob\n",
    "\n",
    "import cv2\n",
    "import pickle5 as pickle\n",
    "from PIL import Image as im\n",
    "import argparse\n",
    "import math\n",
    "import sys\n",
    "import time\n",
    "import copy\n",
    "import numpy as np\n",
    "\n",
    "import keras\n",
    "from keras import regularizers\n",
    "from keras.models import Sequential, Model\n",
    "from keras.layers import Dense, Dropout, Flatten, Activation, BatchNormalization #, regularizers\n",
    "from keras.layers.noise import GaussianNoise\n",
    "from keras.layers import Conv2D, MaxPooling2D,AveragePooling2D\n",
    "from keras import backend as K\n",
    "from keras.callbacks import ModelCheckpoint, EarlyStopping\n",
    "from keras.utils.np_utils import to_categorical\n",
    "import tensorflow as tf\n",
    "import models_custom \n",
    "from keras.models import load_model\n",
    "import glob\n",
    "\n",
    "import os\n",
    "\n",
    "import pandas as pd\n",
    "from tensorflow.tools.docs import doc_controls\n",
    "import librosa, librosa.display\n",
    "import matplotlib.pyplot as plt\n",
    "\n",
    "import os\n",
    "import glob\n",
    "\n",
    "import cv2\n",
    "import pickle5 as pickle\n",
    "from PIL import Image as im\n",
    "import argparse\n",
    "import math\n",
    "import sys\n",
    "import time\n",
    "import copy\n",
    "import numpy as np\n",
    "\n",
    "import keras\n",
    "from keras import regularizers\n",
    "from keras.models import Sequential, Model\n",
    "from keras.layers import Dense, Dropout, Flatten, Activation, BatchNormalization #, regularizers\n",
    "from keras.layers.noise import GaussianNoise\n",
    "from keras.layers import Conv2D, MaxPooling2D,AveragePooling2D\n",
    "from keras import backend as K\n",
    "from keras.callbacks import ModelCheckpoint, EarlyStopping\n",
    "from keras.utils.np_utils import to_categorical\n",
    "import tensorflow as tf\n",
    "import models_custom as mcs\n",
    "from keras.models import load_model\n",
    "import glob\n",
    "\n",
    "import os\n",
    "\n",
    "import pandas as pd\n",
    "from sklearn.model_selection import train_test_split"
   ]
  },
  {
   "cell_type": "raw",
   "id": "d1106a12-1f54-49d2-a66d-05d24acb6533",
   "metadata": {
    "id": "d1106a12-1f54-49d2-a66d-05d24acb6533"
   },
   "source": [
    "--therapist 'Yared Alemu' --emotion 'fear' --name '3CNN2LSTM_Attn' --duration 45 --featureType 'db1' --IsImage 0\n",
    "\n",
    "            elif name=='conv1dlstmAttn'\n",
    "                model=create_conv1dlstmAttn( img_rows, img_cols, filters)\n",
    "            elif name=='LSTM_Attn':\n",
    "                model=create_LSTM_Attn( img_rows, img_cols, filters)\n",
    "            else:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "id": "c4b36dad-0268-44e7-85bc-e93c660ea201",
   "metadata": {
    "id": "c4b36dad-0268-44e7-85bc-e93c660ea201"
   },
   "outputs": [],
   "source": [
    "therapist='Yared Alemu'\n",
    "emotion='anger'\n",
    "name='conv1dlstmAttn' #'LSTM_Attn' #'conv1dlstmAttn', #'shallow' #'3CNN2LSTM_Attn' #'conv1dlstmAttn' #'LSTM_Attn' #'3CNN2LSTM_Attn' #'shallow'\n",
    "use_existing_model= 'no'\n",
    "t=30\n",
    "feat=''\n",
    "img=0"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "id": "69ed7a5c-a607-4a01-862c-75b43d6499fa",
   "metadata": {
    "id": "69ed7a5c-a607-4a01-862c-75b43d6499fa"
   },
   "outputs": [],
   "source": [
    "#export\n",
    "l95=50*30\n",
    "pathG='/content/drive/MyDrive/Pract/data'\n",
    "pathG=\"../data\"\n",
    "suf=''\n",
    "if feat=='db1':\n",
    "    suf='/db1'\n",
    "elif feat=='lib':\n",
    "    suf='/lib'\n",
    "else:\n",
    "    suf=''\n",
    "epochs=100\n",
    "DATASET_PATH0 = pathG+\"/w2v2/w2v2L3\"+suf\n",
    "DATASET_PATH1 = pathG+\"/w2v2/w2v2L5\"+suf\n",
    "DATASET_PATH2 = pathG+\"/w2v2/w2v2L8\"+suf\n",
    "DATASET_PATHS = [DATASET_PATH0,DATASET_PATH1,DATASET_PATH2]\n",
    "\n",
    "chunk_size = 16\n",
    "\n",
    "height=224\n",
    "width=224\n",
    "modname =pathG+'/saved_model/'+therapist+'_'+emotion+'_'+name\n",
    "if use_existing_model=='no':\n",
    "    model=None\n",
    "else:\n",
    "    model = load_model(modname)\n",
    "\n",
    "#https://stackoverflow.com/questions/10443295/combine-3-separate-numpy-arrays-to-an-rgb-image-in-python"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "id": "39de71fc-b947-4d60-bc61-ce174c5e21ad",
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/"
    },
    "executionInfo": {
     "elapsed": 13,
     "status": "ok",
     "timestamp": 1657129863746,
     "user": {
      "displayName": "Sanjeev Singh Kenwar",
      "userId": "00714071671360104547"
     },
     "user_tz": 240
    },
    "id": "39de71fc-b947-4d60-bc61-ce174c5e21ad",
    "outputId": "908b67f2-8485-4a1b-8d53-c30738c2c7b2"
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "30\n",
      "../data/w2v2/w2v2L3\n",
      "../data/saved_model/Yared Alemu_anger_conv1dlstmAttn\n"
     ]
    }
   ],
   "source": [
    "print(t)\n",
    "print(DATASET_PATH0)\n",
    "print(modname)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "id": "1b3819f6-b9a7-4dfa-aa60-b5c701839b2b",
   "metadata": {
    "id": "1b3819f6-b9a7-4dfa-aa60-b5c701839b2b"
   },
   "outputs": [],
   "source": [
    "#export\n",
    "def create_label(therapist,emotion,t, balanced=1):\n",
    "    with open(pathG+'/duration.pickle', 'rb') as f:\n",
    "            dur=pickle.load(f)\n",
    "    with open(pathG+'/fileM.pickle', 'rb') as handle:\n",
    "        fileM= pickle.load(handle)\n",
    "    wavM = [s.replace('pickle', 'wav') for s in fileM]\n",
    "    #dur={key:val for key, val in dur.items() if val <= t}  \n",
    "    fls =list(set(dur.keys()).intersection(set(wavM)))\n",
    "    print(len(fls))\n",
    "    def data_balanced (Alemu):       \n",
    "        emt= Alemu[Alemu.emotion==1]\n",
    "        emtN=Alemu[Alemu.emotion==0]\n",
    "        sz = np.min([emt.shape[0],emtN.shape[0]])\n",
    "        Alemu=pd.concat([emt.sample(sz), emtN.sample(sz)])\n",
    "        return Alemu.sample(frac=1)\n",
    "    df= pd.read_csv(pathG+'/labelsConsolidated.csv')\n",
    "    df = df[df['name'].isin(fls)]\n",
    "    df= df[(df.therapist==therapist) & (df.emotion_type==emotion)]\n",
    "    df['emotion'] = df['rating'].apply(lambda x: 1 if (x.lower()==\"high\" or x.lower()==\"medium\") else 0)\n",
    "    if balanced==1:\n",
    "        df=data_balanced (df)\n",
    "    return df"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "id": "1bf46b56-1aa5-4a15-a12a-d19fbb0c50ff",
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/"
    },
    "executionInfo": {
     "elapsed": 11,
     "status": "ok",
     "timestamp": 1657129863747,
     "user": {
      "displayName": "Sanjeev Singh Kenwar",
      "userId": "00714071671360104547"
     },
     "user_tz": 240
    },
    "id": "1bf46b56-1aa5-4a15-a12a-d19fbb0c50ff",
    "outputId": "9bdf7b6b-b3f5-45e6-bba3-d1eaaf32e19b"
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "1054\n"
     ]
    }
   ],
   "source": [
    "#export\n",
    "\n",
    "df = create_label(therapist,emotion,t, balanced=0)\n",
    "df = df.reset_index()\n",
    "df['name2'] =df['name'].apply (lambda x: x.split(\".\")[0]+\".pickle\")\n",
    "df = df.reset_index() # This redundant did that to avoid some errors\n",
    " "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "id": "8879a3e2-bffc-4aaa-b00c-5bffbd0f8d11",
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/"
    },
    "executionInfo": {
     "elapsed": 166,
     "status": "ok",
     "timestamp": 1657129863905,
     "user": {
      "displayName": "Sanjeev Singh Kenwar",
      "userId": "00714071671360104547"
     },
     "user_tz": 240
    },
    "id": "8879a3e2-bffc-4aaa-b00c-5bffbd0f8d11",
    "outputId": "149a79e0-3451-41eb-8071-f8f39ac88958"
   },
   "outputs": [
    {
     "data": {
      "text/plain": [
       "1500"
      ]
     },
     "execution_count": 7,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "l95"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "id": "cc6a4799-1ebb-4358-8b1a-4b21143481bf",
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/",
     "height": 392
    },
    "executionInfo": {
     "elapsed": 23,
     "status": "ok",
     "timestamp": 1657129863906,
     "user": {
      "displayName": "Sanjeev Singh Kenwar",
      "userId": "00714071671360104547"
     },
     "user_tz": 240
    },
    "id": "cc6a4799-1ebb-4358-8b1a-4b21143481bf",
    "outputId": "ad82890d-a174-4556-f0c1-3d3eeaede175"
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "(1036, 10)\n"
     ]
    },
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>level_0</th>\n",
       "      <th>index</th>\n",
       "      <th>Unnamed: 0</th>\n",
       "      <th>therapist</th>\n",
       "      <th>name</th>\n",
       "      <th>emotion_type</th>\n",
       "      <th>rating</th>\n",
       "      <th>Rating</th>\n",
       "      <th>emotion</th>\n",
       "      <th>name2</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>0</td>\n",
       "      <td>1446</td>\n",
       "      <td>1446</td>\n",
       "      <td>Yared Alemu</td>\n",
       "      <td>1940_39117_1161625039.wav</td>\n",
       "      <td>anger</td>\n",
       "      <td>low</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>1940_39117_1161625039.pickle</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>1</td>\n",
       "      <td>1451</td>\n",
       "      <td>1451</td>\n",
       "      <td>Yared Alemu</td>\n",
       "      <td>6529_53113_3443309365.wav</td>\n",
       "      <td>anger</td>\n",
       "      <td>medium</td>\n",
       "      <td>1</td>\n",
       "      <td>1</td>\n",
       "      <td>6529_53113_3443309365.pickle</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>2</td>\n",
       "      <td>1456</td>\n",
       "      <td>1456</td>\n",
       "      <td>Yared Alemu</td>\n",
       "      <td>9926_39117_1370960430.wav</td>\n",
       "      <td>anger</td>\n",
       "      <td>medium</td>\n",
       "      <td>1</td>\n",
       "      <td>1</td>\n",
       "      <td>9926_39117_1370960430.pickle</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>3</td>\n",
       "      <td>1461</td>\n",
       "      <td>1461</td>\n",
       "      <td>Yared Alemu</td>\n",
       "      <td>4205_39117_2156262111.wav</td>\n",
       "      <td>anger</td>\n",
       "      <td>low</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>4205_39117_2156262111.pickle</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>4</td>\n",
       "      <td>1466</td>\n",
       "      <td>1466</td>\n",
       "      <td>Yared Alemu</td>\n",
       "      <td>1940_39117_1747803047.wav</td>\n",
       "      <td>anger</td>\n",
       "      <td>low</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>1940_39117_1747803047.pickle</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "   level_0  index  Unnamed: 0    therapist                       name  \\\n",
       "0        0   1446        1446  Yared Alemu  1940_39117_1161625039.wav   \n",
       "1        1   1451        1451  Yared Alemu  6529_53113_3443309365.wav   \n",
       "2        2   1456        1456  Yared Alemu  9926_39117_1370960430.wav   \n",
       "3        3   1461        1461  Yared Alemu  4205_39117_2156262111.wav   \n",
       "4        4   1466        1466  Yared Alemu  1940_39117_1747803047.wav   \n",
       "\n",
       "  emotion_type  rating  Rating  emotion                         name2  \n",
       "0        anger     low       0        0  1940_39117_1161625039.pickle  \n",
       "1        anger  medium       1        1  6529_53113_3443309365.pickle  \n",
       "2        anger  medium       1        1  9926_39117_1370960430.pickle  \n",
       "3        anger     low       0        0  4205_39117_2156262111.pickle  \n",
       "4        anger     low       0        0  1940_39117_1747803047.pickle  "
      ]
     },
     "execution_count": 8,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "print(df.shape)\n",
    "df.head()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "id": "63082813-a125-427d-8e63-0672e4fa164f",
   "metadata": {
    "id": "63082813-a125-427d-8e63-0672e4fa164f"
   },
   "outputs": [],
   "source": [
    "#export\n",
    "import pandas as pd\n",
    "def getZ(x): \n",
    "    c=np.array(x[0]).T    \n",
    "    #print(c.shape)\n",
    "    b = np.max(c)\n",
    "    a = np.min(c)\n",
    "    c =(c-a)/(b-a)\n",
    "    c= pd.DataFrame(c)\n",
    "    #c= c.astype('float64')\n",
    "    #print(type(c))\n",
    "    c=c.describe(percentiles=[.1, .25,.5,.75,.90])\n",
    "    #print(c.shape)\n",
    "    c=c.drop(['count'])\n",
    "    c=np.array(c.T)    \n",
    "    return  c"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "id": "6996fb95-9de2-4957-8bfe-7a25fcc56575",
   "metadata": {
    "id": "6996fb95-9de2-4957-8bfe-7a25fcc56575"
   },
   "outputs": [],
   "source": [
    "#export\n",
    "# Normalizing data and creating an array\n",
    "def create_arr(fl,l95, height,width,img): \n",
    "    with open(fl,\"rb\") as f:\n",
    "        x=pickle.load(f) \n",
    "    l1 = x[0].shape[0]\n",
    "    try:\n",
    "        if type(x) is not np.ndarray:\n",
    "            x=x.cpu().detach().numpy()\n",
    "        l95=int(np.ceil(l95/10))*10\n",
    "        #print(\"l95 :\"+str(l95))\n",
    "        if l95>=l1:\n",
    "            x=np.pad(x, ((0,0), (0,l95-l1), (0, 2)), 'constant') \n",
    "        else:\n",
    "            x=x[:,:l95,:]\n",
    "            x=np.pad(x, ((0,0), (0,0), (0, 2)), 'constant')\n",
    "            #print(x.shape)\n",
    "        c= x[0]\n",
    "        b = np.max(c)\n",
    "        a = np.min(c)\n",
    "        c = (c-a)/(b-a)\n",
    "        height=int(x.shape[1]/10)\n",
    "        width=int(x.shape[2]/10)        \n",
    "        if img==1:        \n",
    "            c= 255*c\n",
    "            c= c.astype(np.uint8)\n",
    "            data=im.fromarray(c)\n",
    "            data = data.resize((height,width), im.LANCZOS )\n",
    "            arr=np.array(data)\n",
    "            arr = arr.reshape(height,width,1)\n",
    "            x=None\n",
    "        else:\n",
    "            arr =c             \n",
    "            arr = arr.reshape(arr.shape[0],arr.shape[1],1)\n",
    "            #print(arr.shape)\n",
    "    except Exception as e: # work on python 2.x\n",
    "        #print(\"oops\")\n",
    "        print(str(e))\n",
    "        arr= None     \n",
    "    return arr\n",
    "\n",
    "\n",
    "# In[11]:\n",
    "\n",
    "\n",
    "from os.path import exists\n",
    "# Converting to image\n",
    "def imgconvert(df, l95,DATASET_PATH,height, width, img):\n",
    "    df=df.drop(columns=['level_0'])\n",
    "    df=df.reset_index()\n",
    "    arrlist0=[]\n",
    "    for DATASET_PATH in DATASET_PATHS:\n",
    "        fl= DATASET_PATH +\"/\"+df.iloc[0]['name2']           \n",
    "        if exists(fl)==True:\n",
    "            arrlist0.append(create_arr(fl,l95, height,width,img))\n",
    "        else:\n",
    "            print(fl+\" Does not exists\")\n",
    "    arr= np.concatenate(tuple(arrlist0), axis=2)\n",
    "    #arr = arr.reshape(1, height,width,len(DATASET_PATHS))\n",
    "    arr= np.expand_dims(arr, axis=0)\n",
    "    #print(arr.shape)\n",
    "    #fl= DATASET_PATH +\"/\"+df.iloc[0]['name2']  \n",
    "    #arr=create_arr(fl,l95, height,width,img)\n",
    "    \n",
    "    idx=[]\n",
    "    for i,row in df.iterrows():\n",
    "        #fl = DATASET_PATH+\"/\"+row['name2']\n",
    "        arrlist2=[]\n",
    "        \n",
    "        for DATASET_PATH in DATASET_PATHS:            \n",
    "            fl = DATASET_PATH+\"/\"+row['name2'] \n",
    "            if exists(fl)==True:\n",
    "                arrlist2.append(create_arr(fl,l95, height,width,img)) \n",
    "            else:\n",
    "                print(fl+\" Does not exists\")\n",
    "               \n",
    "        try:\n",
    "            #arr2=create_arr(fl,l95, height,width,img)            \n",
    "            arr2 = np.concatenate(tuple(arrlist2), axis=2)\n",
    "            #arr2 = arr2.reshape(1, height,width,len(DATASET_PATHS))\n",
    "            arr2= np.expand_dims(arr2, axis=0)\n",
    "            arr = np.vstack((arr,arr2))\n",
    "\n",
    "                \n",
    "            idx.append(i)\n",
    "            x=None            \n",
    "        except Exception as e: \n",
    "            #print(\"dhat teri\")\n",
    "            print(str(e))\n",
    "    \n",
    "    arr =np.delete(arr, (0), axis=0) # First row was dummy row\n",
    "    labels=np.array(df.emotion.iloc[idx])\n",
    "    return arr , labels \n",
    "# In[12]:\n",
    "\n",
    "\n",
    "def split_dataframe(df, chunk_size): \n",
    "    chunks = list()\n",
    "    num_chunks = len(df) // chunk_size + 1\n",
    "    for i in range(num_chunks):\n",
    "        chunks.append(df[i*chunk_size:(i+1)*chunk_size])\n",
    "    return chunks\n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 32,
   "id": "cc1f913e-8914-4f02-996a-ff81e95aa118",
   "metadata": {},
   "outputs": [],
   "source": [
    "#export\n",
    "def getarr(frm):\n",
    "    arr=np.zeros(shape=(1,l95,770,3))\n",
    "    lbl=[]\n",
    "    for i,row in frm.iterrows():\n",
    "        a=row[\"name2\"]\n",
    "        fl=pathG+'/w2v2/three/'+a\n",
    "        try:\n",
    "            with open(fl,'rb') as f:\n",
    "                arr2= pickle.load(f)\n",
    "                arr = np.vstack((arr,arr2))\n",
    "                lbl.append(row['emotion'])\n",
    "                #print(b.shape)\n",
    "        except:\n",
    "            pass\n",
    "    arr =np.delete(arr, (0), axis=0) # First row was dummy row\n",
    "    lbl =np.array(lbl)\n",
    "    lbl= lbl.astype(int)\n",
    "    lbl = to_categorical(lbl)\n",
    "    return arr, lbl"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 33,
   "id": "0c4f6493-98d2-4cf1-84dd-ea284dc48df8",
   "metadata": {},
   "outputs": [],
   "source": [
    "#export\n",
    "X= df\n",
    "y= df['emotion']\n",
    "X_train, X_test1, y_train, y_test1 = train_test_split(X, y, test_size=0.2, random_state=42)\n",
    "X_val, X_test, y_val, y_test = train_test_split(X_test1, y_test1, test_size=0.5, random_state=42)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 14,
   "id": "42d2ec59-18c7-4dba-957c-8e52ad641216",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>level_0</th>\n",
       "      <th>index</th>\n",
       "      <th>Unnamed: 0</th>\n",
       "      <th>therapist</th>\n",
       "      <th>name</th>\n",
       "      <th>emotion_type</th>\n",
       "      <th>rating</th>\n",
       "      <th>Rating</th>\n",
       "      <th>emotion</th>\n",
       "      <th>name2</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>921</th>\n",
       "      <td>921</td>\n",
       "      <td>6056</td>\n",
       "      <td>6056</td>\n",
       "      <td>Yared Alemu</td>\n",
       "      <td>6529_53113_304851247.wav</td>\n",
       "      <td>anger</td>\n",
       "      <td>low</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>6529_53113_304851247.pickle</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>791</th>\n",
       "      <td>791</td>\n",
       "      <td>5406</td>\n",
       "      <td>5406</td>\n",
       "      <td>Yared Alemu</td>\n",
       "      <td>6708_53113_1571184000.wav</td>\n",
       "      <td>anger</td>\n",
       "      <td>low</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>6708_53113_1571184000.pickle</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>52</th>\n",
       "      <td>52</td>\n",
       "      <td>1706</td>\n",
       "      <td>1706</td>\n",
       "      <td>Yared Alemu</td>\n",
       "      <td>3720_39117_1587513600.wav</td>\n",
       "      <td>anger</td>\n",
       "      <td>medium</td>\n",
       "      <td>1</td>\n",
       "      <td>1</td>\n",
       "      <td>3720_39117_1587513600.pickle</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>878</th>\n",
       "      <td>878</td>\n",
       "      <td>5841</td>\n",
       "      <td>5841</td>\n",
       "      <td>Yared Alemu</td>\n",
       "      <td>6709_53113_1570147200.wav</td>\n",
       "      <td>anger</td>\n",
       "      <td>medium</td>\n",
       "      <td>1</td>\n",
       "      <td>1</td>\n",
       "      <td>6709_53113_1570147200.pickle</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>337</th>\n",
       "      <td>337</td>\n",
       "      <td>3136</td>\n",
       "      <td>3136</td>\n",
       "      <td>Yared Alemu</td>\n",
       "      <td>8161_39117_3739798004.wav</td>\n",
       "      <td>anger</td>\n",
       "      <td>none</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>8161_39117_3739798004.pickle</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "     level_0  index  Unnamed: 0    therapist                       name  \\\n",
       "921      921   6056        6056  Yared Alemu   6529_53113_304851247.wav   \n",
       "791      791   5406        5406  Yared Alemu  6708_53113_1571184000.wav   \n",
       "52        52   1706        1706  Yared Alemu  3720_39117_1587513600.wav   \n",
       "878      878   5841        5841  Yared Alemu  6709_53113_1570147200.wav   \n",
       "337      337   3136        3136  Yared Alemu  8161_39117_3739798004.wav   \n",
       "\n",
       "    emotion_type  rating  Rating  emotion                         name2  \n",
       "921        anger     low       0        0   6529_53113_304851247.pickle  \n",
       "791        anger     low       0        0  6708_53113_1571184000.pickle  \n",
       "52         anger  medium       1        1  3720_39117_1587513600.pickle  \n",
       "878        anger  medium       1        1  6709_53113_1570147200.pickle  \n",
       "337        anger    none       0        0  8161_39117_3739798004.pickle  "
      ]
     },
     "execution_count": 14,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "X_train.head()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 34,
   "id": "2437666f-8472-4fe2-835d-734ddcd331ef",
   "metadata": {
    "id": "2437666f-8472-4fe2-835d-734ddcd331ef"
   },
   "outputs": [
    {
     "data": {
      "text/plain": [
       "'\\nval_x, val_y =imgconvert(X_val,l95,DATASET_PATHS,height, width, img)\\ntest_x, test_y =imgconvert(X_val,l95,DATASET_PATHS,height, width, img)\\nval_y=val_y.astype(int) \\ntest_y=test_y.astype(int) \\ny_val = to_categorical(val_y)\\ny_test= to_categorical(test_y)\\n'"
      ]
     },
     "execution_count": 34,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "#export\n",
    "val_x,y_val = getarr(X_val)\n",
    "test_x,y_test = getarr(X_test)\n",
    "'''\n",
    "val_x, val_y =imgconvert(X_val,l95,DATASET_PATHS,height, width, img)\n",
    "test_x, test_y =imgconvert(X_val,l95,DATASET_PATHS,height, width, img)\n",
    "val_y=val_y.astype(int) \n",
    "test_y=test_y.astype(int) \n",
    "y_val = to_categorical(val_y)\n",
    "y_test= to_categorical(test_y)\n",
    "'''\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 38,
   "id": "76907dec-f041-42ec-89a7-12f433c3fc2d",
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/",
     "height": 53
    },
    "executionInfo": {
     "elapsed": 44,
     "status": "ok",
     "timestamp": 1657130227109,
     "user": {
      "displayName": "Sanjeev Singh Kenwar",
      "userId": "00714071671360104547"
     },
     "user_tz": 240
    },
    "id": "76907dec-f041-42ec-89a7-12f433c3fc2d",
    "outputId": "d1118030-1bfd-46ae-b36c-8c8d564f87d2"
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "(104, 1500, 770, 3)\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "'conv1dlstmAttn'"
      ]
     },
     "execution_count": 38,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "print(val_x.shape)\n",
    "name\n",
    "#use_existing_model"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 39,
   "id": "ea4c2537-04dd-46d8-a02a-6c94d253b6e1",
   "metadata": {
    "id": "ea4c2537-04dd-46d8-a02a-6c94d253b6e1"
   },
   "outputs": [],
   "source": [
    "model=None\n",
    "use_existing_model='no'"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "0a595188-b4ca-4780-ac8d-68322f109e17",
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/"
    },
    "id": "0a595188-b4ca-4780-ac8d-68322f109e17",
    "outputId": "88392324-59ac-4961-f111-7fc2812b080b"
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "(16, 1500, 770, 3) (16, 2)\n",
      "Model is None\n",
      "Now working on conv1dlstmAttn\n",
      "model does not existing. Creating a new one\n",
      "Epoch 1/100\n",
      "1/1 [==============================] - 82s 82s/step - loss: 0.7345 - recall: 0.3750 - val_loss: 0.6932 - val_recall: 0.5192\n",
      "Epoch 2/100\n",
      "1/1 [==============================] - 77s 77s/step - loss: 0.7644 - recall: 0.4375 - val_loss: 0.6931 - val_recall: 0.5385\n",
      "Epoch 3/100\n",
      "1/1 [==============================] - 77s 77s/step - loss: 0.7041 - recall: 0.5000 - val_loss: 0.6931 - val_recall: 0.5385\n",
      "Epoch 4/100\n",
      "1/1 [==============================] - 76s 76s/step - loss: 0.6205 - recall: 0.7500 - val_loss: 0.6931 - val_recall: 0.5385\n",
      "Epoch 5/100\n",
      "1/1 [==============================] - 75s 75s/step - loss: 0.6315 - recall: 0.6875 - val_loss: 0.6930 - val_recall: 0.5385\n",
      "Epoch 6/100\n"
     ]
    }
   ],
   "source": [
    "#export\n",
    "import importlib\n",
    "importlib.reload(models_custom)\n",
    "chunks=split_dataframe(X_train,chunk_size)\n",
    "\n",
    "for chunk in chunks[0:len(chunks)]:\n",
    "    chunk=chunk.drop(columns=['level_0'])\n",
    "    chunk=chunk.reset_index()\n",
    "    try:\n",
    "        '''\n",
    "        train_x, train_y =imgconvert(chunk,l95,DATASET_PATHS,height, width, img)\n",
    "        train_y=train_y.astype(int)       \n",
    "        # one hot encode outputs\n",
    "        y_train = to_categorical(train_y) \n",
    "        '''\n",
    "        train_x, y_train = getarr(chunk)\n",
    "        print(train_x.shape, y_train.shape)\n",
    "        therp = therapist.replace(\" \",\"\")\n",
    "        modname ='saved_model/'+therp+'_'+emotion+'_'+name\n",
    "        if model==None:\n",
    "            print(\"Model is None\")\n",
    "            print(\"Now working on \"+ name)\n",
    "        model, history= models_custom.call_model( use_existing_model,model,therp, emotion, train_x, y_train, val_x, y_val, train_x.shape[0],  modname, name, epochs  )      \n",
    "      \n",
    "        \n",
    "    except Exception as e:\n",
    "        print(str(e))\n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "8243445f-b11a-4b64-b434-6a7be6c3a406",
   "metadata": {
    "id": "8243445f-b11a-4b64-b434-6a7be6c3a406"
   },
   "outputs": [],
   "source": [
    "#export\n",
    "\n",
    "score = model.evaluate(test_x, y_test, verbose=1)\n",
    "\n",
    "#print loss and accuracy\n",
    "print('Test loss:', score[0])\n",
    "print('Test accuracy:', score[1])\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "6e029591-b134-4470-ad36-611de7d06042",
   "metadata": {
    "id": "6e029591-b134-4470-ad36-611de7d06042"
   },
   "outputs": [],
   "source": [
    "preds= model.predict(test_x)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "e5538d01-bf28-4b3b-9be7-ac67ac3b2633",
   "metadata": {
    "id": "e5538d01-bf28-4b3b-9be7-ac67ac3b2633"
   },
   "outputs": [],
   "source": [
    "b= np.where(preds > .5, 1, 0)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "54f4d688-32f2-49ec-9a6f-696c74dbb0b0",
   "metadata": {
    "id": "54f4d688-32f2-49ec-9a6f-696c74dbb0b0"
   },
   "outputs": [],
   "source": [
    "153/232"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "5f838549-9e6f-488f-b254-708cf4b49f36",
   "metadata": {
    "id": "5f838549-9e6f-488f-b254-708cf4b49f36"
   },
   "outputs": [],
   "source": [
    "y_test.sum(axis=0)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "ad3b8aee-1b97-4ace-a3b4-d645e0055b82",
   "metadata": {
    "id": "ad3b8aee-1b97-4ace-a3b4-d645e0055b82"
   },
   "outputs": [],
   "source": [
    "from sklearn.metrics import confusion_matrix\n",
    "\n",
    "\n",
    "\n",
    "conf_mat = confusion_matrix(y_test, model.predict(test_x))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "7cb977c6-fe78-4909-9f64-33b25c5a4a98",
   "metadata": {
    "id": "7cb977c6-fe78-4909-9f64-33b25c5a4a98"
   },
   "outputs": [],
   "source": [
    "#export\n",
    "import time\n",
    "  \n",
    "# ts stores the time in seconds\n",
    "ts = time.time()\n",
    "\n",
    "f = open(\"results.txt\", \"a\")\n",
    "f.write(str(ts)+'|'+therapist+'|'+emotion+'|'+name+'|'+str(score[1])+'\\n')\n",
    "f.close()\n",
    "\n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "586fc0db-808d-4376-b912-58aad20a0058",
   "metadata": {
    "id": "586fc0db-808d-4376-b912-58aad20a0058"
   },
   "outputs": [],
   "source": [
    "#nbdev_build_lib --fname master.ipynb\n",
    "#python master.py --therapist 'Yared Alemu' --emotion 'fear' --name '3CNN2LSTM_Attn'"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "4c2b7008-984b-412e-b40d-cd2ac5e7ff6e",
   "metadata": {
    "id": "4c2b7008-984b-412e-b40d-cd2ac5e7ff6e"
   },
   "outputs": [],
   "source": [
    "from numba import cuda \n",
    "device = cuda.get_current_device()\n",
    "device.reset()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "a01ba09c-ebf6-4b8c-9701-ea0c08d317fd",
   "metadata": {
    "id": "a01ba09c-ebf6-4b8c-9701-ea0c08d317fd"
   },
   "outputs": [],
   "source": [
    "DATASET_PATH0"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "d09e2f08-30a7-4171-94a7-c7eb66d65a3f",
   "metadata": {
    "id": "d09e2f08-30a7-4171-94a7-c7eb66d65a3f"
   },
   "outputs": [],
   "source": [
    "#export\n",
    "if __name__ == '__main__':\n",
    "    pass"
   ]
  }
 ],
 "metadata": {
  "accelerator": "TPU",
  "colab": {
   "collapsed_sections": [],
   "machine_shape": "hm",
   "name": "master.ipynb",
   "provenance": []
  },
  "gpuClass": "standard",
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.8.10"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
